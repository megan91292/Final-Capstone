{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,precision_recall_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support,f1_score,fbeta_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC, NuSVC, LinearSVC\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import ast\n",
    "\n",
    "import keras\n",
    "plt.rcParams['figure.figsize'] = (17, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File data.csv does not exist: 'data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6456521db808>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File data.csv does not exist: 'data.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = pd.read_csv('data/fma_metadata/genrelist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres.rename({'Unnamed: 0':'track_id'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = genres.drop(index=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres['track_id'] = genres['track_id'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename({'filename':'track_id'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['track_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.merge(df,genres,on='track_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Instrumental\n",
       "1        Experimental\n",
       "2                Folk\n",
       "3             Hip-Hop\n",
       "4             Hip-Hop\n",
       "            ...      \n",
       "7992    International\n",
       "7993     Experimental\n",
       "7994              Pop\n",
       "7995     Experimental\n",
       "7996     Instrumental\n",
       "Name: genre, Length: 7997, dtype: object"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('track_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_cqt</th>\n",
       "      <th>chroma_cens</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>spectral_contrast</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>tonnetz</th>\n",
       "      <th>mfcc1</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc13</th>\n",
       "      <th>mfcc14</th>\n",
       "      <th>mfcc15</th>\n",
       "      <th>mfcc16</th>\n",
       "      <th>mfcc17</th>\n",
       "      <th>mfcc18</th>\n",
       "      <th>mfcc19</th>\n",
       "      <th>mfcc20</th>\n",
       "      <th>genre</th>\n",
       "      <th>testtrainval</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126014</th>\n",
       "      <td>0.267008</td>\n",
       "      <td>0.171130</td>\n",
       "      <td>0.237383</td>\n",
       "      <td>699.229710</td>\n",
       "      <td>785.999971</td>\n",
       "      <td>25.676751</td>\n",
       "      <td>1183.751175</td>\n",
       "      <td>0.041712</td>\n",
       "      <td>0.092841</td>\n",
       "      <td>-352.161438</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.659972</td>\n",
       "      <td>-13.275584</td>\n",
       "      <td>-12.988043</td>\n",
       "      <td>-15.687397</td>\n",
       "      <td>-12.339302</td>\n",
       "      <td>2.211766</td>\n",
       "      <td>2.147864</td>\n",
       "      <td>-5.011512</td>\n",
       "      <td>Instrumental</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54496</th>\n",
       "      <td>0.274600</td>\n",
       "      <td>0.207362</td>\n",
       "      <td>0.277710</td>\n",
       "      <td>1833.074733</td>\n",
       "      <td>2091.124342</td>\n",
       "      <td>25.274995</td>\n",
       "      <td>3818.560243</td>\n",
       "      <td>0.093890</td>\n",
       "      <td>0.044640</td>\n",
       "      <td>-290.169464</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.247772</td>\n",
       "      <td>3.441898</td>\n",
       "      <td>-0.244973</td>\n",
       "      <td>4.090439</td>\n",
       "      <td>-1.278771</td>\n",
       "      <td>9.071951</td>\n",
       "      <td>-0.169724</td>\n",
       "      <td>0.161876</td>\n",
       "      <td>Experimental</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65893</th>\n",
       "      <td>0.458305</td>\n",
       "      <td>0.253559</td>\n",
       "      <td>0.412075</td>\n",
       "      <td>2767.487106</td>\n",
       "      <td>2741.112704</td>\n",
       "      <td>20.450162</td>\n",
       "      <td>5889.689386</td>\n",
       "      <td>0.111506</td>\n",
       "      <td>0.013648</td>\n",
       "      <td>-80.027184</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.908488</td>\n",
       "      <td>3.085722</td>\n",
       "      <td>-3.682684</td>\n",
       "      <td>2.957125</td>\n",
       "      <td>-2.243021</td>\n",
       "      <td>1.578797</td>\n",
       "      <td>-4.537785</td>\n",
       "      <td>1.052801</td>\n",
       "      <td>Folk</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71158</th>\n",
       "      <td>0.531325</td>\n",
       "      <td>0.258276</td>\n",
       "      <td>0.424391</td>\n",
       "      <td>1444.225428</td>\n",
       "      <td>2060.084462</td>\n",
       "      <td>19.861984</td>\n",
       "      <td>3089.631317</td>\n",
       "      <td>0.046734</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-123.564980</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.089045</td>\n",
       "      <td>2.822888</td>\n",
       "      <td>-2.630777</td>\n",
       "      <td>1.943587</td>\n",
       "      <td>-7.131413</td>\n",
       "      <td>1.516889</td>\n",
       "      <td>-0.094114</td>\n",
       "      <td>-0.776687</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57821</th>\n",
       "      <td>0.412456</td>\n",
       "      <td>0.239312</td>\n",
       "      <td>0.335196</td>\n",
       "      <td>2253.305912</td>\n",
       "      <td>2412.719760</td>\n",
       "      <td>22.327731</td>\n",
       "      <td>4858.028957</td>\n",
       "      <td>0.099870</td>\n",
       "      <td>0.024816</td>\n",
       "      <td>-71.340874</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.891809</td>\n",
       "      <td>-2.783748</td>\n",
       "      <td>-6.777088</td>\n",
       "      <td>-3.736772</td>\n",
       "      <td>-11.871335</td>\n",
       "      <td>-0.826213</td>\n",
       "      <td>-2.934075</td>\n",
       "      <td>6.011378</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          chroma_cqt  chroma_cens  chroma_stft  spectral_centroid  \\\n",
       "track_id                                                            \n",
       "126014      0.267008     0.171130     0.237383         699.229710   \n",
       "54496       0.274600     0.207362     0.277710        1833.074733   \n",
       "65893       0.458305     0.253559     0.412075        2767.487106   \n",
       "71158       0.531325     0.258276     0.424391        1444.225428   \n",
       "57821       0.412456     0.239312     0.335196        2253.305912   \n",
       "\n",
       "          spectral_bandwidth  spectral_contrast      rolloff  \\\n",
       "track_id                                                       \n",
       "126014            785.999971          25.676751  1183.751175   \n",
       "54496            2091.124342          25.274995  3818.560243   \n",
       "65893            2741.112704          20.450162  5889.689386   \n",
       "71158            2060.084462          19.861984  3089.631317   \n",
       "57821            2412.719760          22.327731  4858.028957   \n",
       "\n",
       "          zero_crossing_rate   tonnetz       mfcc1  ...     mfcc13     mfcc14  \\\n",
       "track_id                                            ...                         \n",
       "126014              0.041712  0.092841 -352.161438  ... -12.659972 -13.275584   \n",
       "54496               0.093890  0.044640 -290.169464  ...  -6.247772   3.441898   \n",
       "65893               0.111506  0.013648  -80.027184  ...  -2.908488   3.085722   \n",
       "71158               0.046734  0.000029 -123.564980  ...  -1.089045   2.822888   \n",
       "57821               0.099870  0.024816  -71.340874  ...  -8.891809  -2.783748   \n",
       "\n",
       "             mfcc15     mfcc16     mfcc17    mfcc18    mfcc19    mfcc20  \\\n",
       "track_id                                                                  \n",
       "126014   -12.988043 -15.687397 -12.339302  2.211766  2.147864 -5.011512   \n",
       "54496     -0.244973   4.090439  -1.278771  9.071951 -0.169724  0.161876   \n",
       "65893     -3.682684   2.957125  -2.243021  1.578797 -4.537785  1.052801   \n",
       "71158     -2.630777   1.943587  -7.131413  1.516889 -0.094114 -0.776687   \n",
       "57821     -6.777088  -3.736772 -11.871335 -0.826213 -2.934075  6.011378   \n",
       "\n",
       "                 genre  testtrainval  \n",
       "track_id                              \n",
       "126014    Instrumental      training  \n",
       "54496     Experimental      training  \n",
       "65893             Folk      training  \n",
       "71158          Hip-Hop      training  \n",
       "57821          Hip-Hop      training  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[['genre']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['genre','testtrainval'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train , y_test = train_test_split(X,y,stratify=y,test_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train , y_val = train_test_split(X_train,y_train,stratify=y_train,test_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5997, 29), (1000, 29), (1000, 29))"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape,X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>track_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15210</th>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121315</th>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45387</th>\n",
       "      <td>Instrumental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90824</th>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148613</th>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28179</th>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126490</th>\n",
       "      <td>Folk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hip-Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66636</th>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109900</th>\n",
       "      <td>Folk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 genre\n",
       "track_id              \n",
       "15210          Hip-Hop\n",
       "121315         Hip-Hop\n",
       "45387     Instrumental\n",
       "90824              Pop\n",
       "148613             Pop\n",
       "...                ...\n",
       "28179       Electronic\n",
       "126490            Folk\n",
       "2              Hip-Hop\n",
       "66636       Electronic\n",
       "109900            Folk\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer,OneHotEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the product labels to numerical values\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(y_train)\n",
    "\n",
    "y_train_lb = to_categorical(lb.transform(y_train))[:, :, 1]\n",
    "y_val_lb = to_categorical(lb.transform(y_val))[:, :, 1]\n",
    "y_test_lb = to_categorical(lb.transform(y_test))[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_lab = labels.fit_transform(y_train)\n",
    "y_test_lab = labels.transform(y_test)\n",
    "y_val_lab = labels.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.49891385, -0.35806126, -0.83527725, ..., -0.60946987,\n",
       "        -0.12014237, -0.60595854],\n",
       "       [-0.98905821, -0.94087328, -0.69181612, ..., -0.4853615 ,\n",
       "         0.20259553,  0.79872898],\n",
       "       [ 0.86361034,  1.1664658 , -0.3881585 , ..., -0.80999204,\n",
       "         0.08697596,  1.16571036],\n",
       "       ...,\n",
       "       [ 0.88612734,  1.15699134,  0.28377595, ...,  0.18346541,\n",
       "         0.05385226, -0.93523652],\n",
       "       [ 0.79256391,  0.57963453, -0.62610225, ...,  1.33386349,\n",
       "         1.04306505,  1.27048159],\n",
       "       [-1.25824188, -1.60073274, -1.1038575 , ...,  0.44572557,\n",
       "         0.94935561,  1.46154193]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5997 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "5997/5997 [==============================] - 1s 138us/step - loss: 1.7742 - acc: 0.3508 - val_loss: 1.5699 - val_acc: 0.4320\n",
      "Epoch 2/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.5689 - acc: 0.4404 - val_loss: 1.4987 - val_acc: 0.4640\n",
      "Epoch 3/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.4916 - acc: 0.4654 - val_loss: 1.4649 - val_acc: 0.4590\n",
      "Epoch 4/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.4382 - acc: 0.4884 - val_loss: 1.4402 - val_acc: 0.4700\n",
      "Epoch 5/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.3916 - acc: 0.5034 - val_loss: 1.4451 - val_acc: 0.4690\n",
      "Epoch 6/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.3494 - acc: 0.5184 - val_loss: 1.4304 - val_acc: 0.4790\n",
      "Epoch 7/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.3156 - acc: 0.5294 - val_loss: 1.4204 - val_acc: 0.4950\n",
      "Epoch 8/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.2644 - acc: 0.5484 - val_loss: 1.4218 - val_acc: 0.4900\n",
      "Epoch 9/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.2391 - acc: 0.5573 - val_loss: 1.4123 - val_acc: 0.4910\n",
      "Epoch 10/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.1972 - acc: 0.5720 - val_loss: 1.4169 - val_acc: 0.5020\n",
      "Epoch 11/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.1659 - acc: 0.5806 - val_loss: 1.4422 - val_acc: 0.4990\n",
      "Epoch 12/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.1317 - acc: 0.5921 - val_loss: 1.4218 - val_acc: 0.5090\n",
      "Epoch 13/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.0901 - acc: 0.6161 - val_loss: 1.4241 - val_acc: 0.5080\n",
      "Epoch 14/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.0524 - acc: 0.6290 - val_loss: 1.4399 - val_acc: 0.5090\n",
      "Epoch 15/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.0202 - acc: 0.6397 - val_loss: 1.4552 - val_acc: 0.4970\n",
      "Epoch 16/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 0.9935 - acc: 0.6512 - val_loss: 1.4571 - val_acc: 0.5010\n",
      "Epoch 17/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.9587 - acc: 0.6583 - val_loss: 1.4608 - val_acc: 0.4960\n",
      "Epoch 18/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 0.9253 - acc: 0.6747 - val_loss: 1.4728 - val_acc: 0.5090\n",
      "Epoch 19/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.8917 - acc: 0.6900 - val_loss: 1.5211 - val_acc: 0.5020\n",
      "Epoch 20/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.8569 - acc: 0.7065 - val_loss: 1.5638 - val_acc: 0.5030\n",
      "Epoch 21/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.8236 - acc: 0.7162 - val_loss: 1.5339 - val_acc: 0.5120\n",
      "Epoch 22/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.8006 - acc: 0.7227 - val_loss: 1.5450 - val_acc: 0.5060\n",
      "Epoch 23/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.7635 - acc: 0.7394 - val_loss: 1.5603 - val_acc: 0.4970\n",
      "Epoch 24/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 0.7373 - acc: 0.7492 - val_loss: 1.6387 - val_acc: 0.4900\n",
      "Epoch 25/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 0.7235 - acc: 0.7567 - val_loss: 1.6370 - val_acc: 0.4990\n",
      "Epoch 26/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.6769 - acc: 0.7749 - val_loss: 1.6409 - val_acc: 0.4950\n",
      "Epoch 27/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.6462 - acc: 0.7889 - val_loss: 1.6989 - val_acc: 0.4950\n",
      "Epoch 28/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.6215 - acc: 0.7967 - val_loss: 1.7084 - val_acc: 0.4960\n",
      "Epoch 29/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.5928 - acc: 0.8087 - val_loss: 1.8015 - val_acc: 0.4820\n",
      "Epoch 30/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 0.5733 - acc: 0.8099 - val_loss: 1.8133 - val_acc: 0.4860\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.Dense(512, activation='relu'))\n",
    "\n",
    "\n",
    "model.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train_lab,\n",
    "                    epochs=30,\n",
    "                    batch_size=128,validation_data=(X_val,y_val_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5997 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "5997/5997 [==============================] - 1s 149us/step - loss: 1.7712 - acc: 0.3465 - val_loss: 1.5886 - val_acc: 0.4190\n",
      "Epoch 2/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.5739 - acc: 0.4319 - val_loss: 1.5238 - val_acc: 0.4410\n",
      "Epoch 3/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.5133 - acc: 0.4617 - val_loss: 1.4882 - val_acc: 0.4440\n",
      "Epoch 4/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.4618 - acc: 0.4737 - val_loss: 1.4742 - val_acc: 0.4550\n",
      "Epoch 5/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.4281 - acc: 0.4911 - val_loss: 1.4420 - val_acc: 0.4610\n",
      "Epoch 6/30\n",
      "5997/5997 [==============================] - 0s 15us/step - loss: 1.3917 - acc: 0.5074 - val_loss: 1.4283 - val_acc: 0.4670\n",
      "Epoch 7/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.3578 - acc: 0.5153 - val_loss: 1.4196 - val_acc: 0.4770\n",
      "Epoch 8/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.3264 - acc: 0.5304 - val_loss: 1.4270 - val_acc: 0.4700\n",
      "Epoch 9/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.2987 - acc: 0.5384 - val_loss: 1.4219 - val_acc: 0.4750\n",
      "Epoch 10/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.2666 - acc: 0.5523 - val_loss: 1.4032 - val_acc: 0.4970\n",
      "Epoch 11/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.2399 - acc: 0.5614 - val_loss: 1.4076 - val_acc: 0.4920\n",
      "Epoch 12/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.2174 - acc: 0.5780 - val_loss: 1.4134 - val_acc: 0.4870\n",
      "Epoch 13/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.1884 - acc: 0.5871 - val_loss: 1.4105 - val_acc: 0.4870\n",
      "Epoch 14/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.1686 - acc: 0.5825 - val_loss: 1.4183 - val_acc: 0.4780\n",
      "Epoch 15/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.1436 - acc: 0.5993 - val_loss: 1.4151 - val_acc: 0.4840\n",
      "Epoch 16/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.1164 - acc: 0.6133 - val_loss: 1.4172 - val_acc: 0.4930\n",
      "Epoch 17/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.0915 - acc: 0.6206 - val_loss: 1.4039 - val_acc: 0.5040\n",
      "Epoch 18/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.0660 - acc: 0.6265 - val_loss: 1.4195 - val_acc: 0.5120\n",
      "Epoch 19/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.0475 - acc: 0.6320 - val_loss: 1.4110 - val_acc: 0.5090\n",
      "Epoch 20/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.0154 - acc: 0.6522 - val_loss: 1.4237 - val_acc: 0.4900\n",
      "Epoch 21/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 0.9984 - acc: 0.6565 - val_loss: 1.4322 - val_acc: 0.5080\n",
      "Epoch 22/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 0.9771 - acc: 0.6610 - val_loss: 1.4236 - val_acc: 0.5020\n",
      "Epoch 23/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.9547 - acc: 0.6740 - val_loss: 1.4416 - val_acc: 0.4950\n",
      "Epoch 24/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.9327 - acc: 0.6830 - val_loss: 1.4587 - val_acc: 0.5030\n",
      "Epoch 25/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 0.9087 - acc: 0.6903 - val_loss: 1.4645 - val_acc: 0.5020\n",
      "Epoch 26/30\n",
      "5997/5997 [==============================] - 0s 15us/step - loss: 0.8966 - acc: 0.6918 - val_loss: 1.4762 - val_acc: 0.5110\n",
      "Epoch 27/30\n",
      "5997/5997 [==============================] - 0s 15us/step - loss: 0.8670 - acc: 0.7104 - val_loss: 1.4815 - val_acc: 0.5110\n",
      "Epoch 28/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 0.8529 - acc: 0.7142 - val_loss: 1.4913 - val_acc: 0.5120\n",
      "Epoch 29/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 0.8346 - acc: 0.7225 - val_loss: 1.5101 - val_acc: 0.5030\n",
      "Epoch 30/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 0.8144 - acc: 0.7272 - val_loss: 1.5190 - val_acc: 0.5060\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "# model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.Dense(512, activation='relu'))\n",
    "\n",
    "\n",
    "model.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train_lab,\n",
    "                    epochs=30,\n",
    "                    batch_size=128,validation_data=(X_val,y_val_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5997/5997 [==============================] - 0s 31us/step\n",
      "----------\n",
      "Training Loss: 0.77 \n",
      "Training Accuracy: 0.743\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_train, y_train_lab)\n",
    "print('----------')\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 32us/step\n",
      "----------\n",
      "Training Loss: 1.62 \n",
      "Training Accuracy: 0.434\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(X_test, y_test_lab)\n",
    "print('----------')\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "baseline_model = models.Sequential()\n",
    "baseline_model.add(layers.Dense(256, activation='relu', input_shape=(29,)))\n",
    "baseline_model.add(layers.Dense(128, activation='relu'))\n",
    "baseline_model.add(layers.Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "baseline_model.compile(optimizer='nadam', \n",
    "                       loss='sparse_categorical_crossentropy', \n",
    "                       metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5997 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "5997/5997 [==============================] - 1s 173us/step - loss: 1.7067 - acc: 0.3725 - val_loss: 1.5316 - val_acc: 0.4560\n",
      "Epoch 2/50\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.5284 - acc: 0.4481 - val_loss: 1.4713 - val_acc: 0.4670\n",
      "Epoch 3/50\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.4560 - acc: 0.4764 - val_loss: 1.4610 - val_acc: 0.4640\n",
      "Epoch 4/50\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.4023 - acc: 0.4919 - val_loss: 1.4146 - val_acc: 0.4890\n",
      "Epoch 5/50\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.3507 - acc: 0.5148 - val_loss: 1.4209 - val_acc: 0.4870\n",
      "Epoch 6/50\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.3066 - acc: 0.5418 - val_loss: 1.4501 - val_acc: 0.4610\n",
      "Epoch 7/50\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.2600 - acc: 0.5474 - val_loss: 1.4070 - val_acc: 0.4930\n",
      "Epoch 8/50\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 1.2176 - acc: 0.5676 - val_loss: 1.4145 - val_acc: 0.4950\n",
      "Epoch 9/50\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 1.1711 - acc: 0.5851 - val_loss: 1.4477 - val_acc: 0.4850\n",
      "Epoch 10/50\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 1.1429 - acc: 0.5920 - val_loss: 1.4111 - val_acc: 0.5060\n",
      "Epoch 11/50\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 1.0975 - acc: 0.6096 - val_loss: 1.4292 - val_acc: 0.4950\n",
      "Epoch 12/50\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.0572 - acc: 0.6330 - val_loss: 1.4589 - val_acc: 0.4860\n",
      "Epoch 13/50\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.0287 - acc: 0.6350 - val_loss: 1.4609 - val_acc: 0.4850\n",
      "Epoch 14/50\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.9849 - acc: 0.6563 - val_loss: 1.4854 - val_acc: 0.4960\n",
      "Epoch 15/50\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 0.9462 - acc: 0.6705 - val_loss: 1.5310 - val_acc: 0.4820\n",
      "Epoch 16/50\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 0.9186 - acc: 0.6803 - val_loss: 1.5026 - val_acc: 0.4860\n",
      "Epoch 17/50\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.8805 - acc: 0.6993 - val_loss: 1.5292 - val_acc: 0.4860\n",
      "Epoch 18/50\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 0.8449 - acc: 0.7102 - val_loss: 1.5292 - val_acc: 0.4850\n",
      "Epoch 19/50\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 0.8079 - acc: 0.7264 - val_loss: 1.5803 - val_acc: 0.4820\n",
      "Epoch 20/50\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 0.7750 - acc: 0.7420 - val_loss: 1.5949 - val_acc: 0.4850\n",
      "Epoch 21/50\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.7347 - acc: 0.7584 - val_loss: 1.6192 - val_acc: 0.4830\n",
      "Epoch 22/50\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.7108 - acc: 0.7639 - val_loss: 1.6475 - val_acc: 0.4740\n",
      "Epoch 23/50\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 0.6795 - acc: 0.7756 - val_loss: 1.6827 - val_acc: 0.4690\n",
      "Epoch 24/50\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.6454 - acc: 0.7859 - val_loss: 1.7036 - val_acc: 0.4920\n",
      "Epoch 25/50\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.6176 - acc: 0.8002 - val_loss: 1.7587 - val_acc: 0.4810\n",
      "Epoch 26/50\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.5897 - acc: 0.8144 - val_loss: 1.7723 - val_acc: 0.4680\n",
      "Epoch 27/50\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.5546 - acc: 0.8274 - val_loss: 1.8799 - val_acc: 0.4600\n",
      "Epoch 28/50\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.5331 - acc: 0.8281 - val_loss: 1.8671 - val_acc: 0.4630\n",
      "Epoch 29/50\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.4989 - acc: 0.8478 - val_loss: 1.9137 - val_acc: 0.4620\n",
      "Epoch 30/50\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 0.4727 - acc: 0.8548 - val_loss: 1.9052 - val_acc: 0.4740\n",
      "Epoch 31/50\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 0.4455 - acc: 0.8683 - val_loss: 1.9612 - val_acc: 0.4960\n",
      "Epoch 32/50\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.4345 - acc: 0.8714 - val_loss: 1.9630 - val_acc: 0.4690\n",
      "Epoch 33/50\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 0.4093 - acc: 0.8778 - val_loss: 2.0311 - val_acc: 0.4680\n",
      "Epoch 34/50\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 0.3936 - acc: 0.8838 - val_loss: 2.0341 - val_acc: 0.4870\n",
      "Epoch 35/50\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 0.3642 - acc: 0.9005 - val_loss: 2.0410 - val_acc: 0.4750\n",
      "Epoch 36/50\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 0.3338 - acc: 0.9090 - val_loss: 2.1528 - val_acc: 0.4800\n",
      "Epoch 37/50\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 0.3218 - acc: 0.9138 - val_loss: 2.1363 - val_acc: 0.4750\n",
      "Epoch 38/50\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 0.3039 - acc: 0.9203 - val_loss: 2.1947 - val_acc: 0.4740\n",
      "Epoch 39/50\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.2801 - acc: 0.9301 - val_loss: 2.2510 - val_acc: 0.4680\n",
      "Epoch 40/50\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 0.2552 - acc: 0.9386 - val_loss: 2.2634 - val_acc: 0.4570\n",
      "Epoch 41/50\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.2412 - acc: 0.9413 - val_loss: 2.3221 - val_acc: 0.4590\n",
      "Epoch 42/50\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 0.2275 - acc: 0.9476 - val_loss: 2.3637 - val_acc: 0.4750\n",
      "Epoch 43/50\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 0.2109 - acc: 0.9518 - val_loss: 2.3846 - val_acc: 0.4630\n",
      "Epoch 44/50\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 0.2024 - acc: 0.9563 - val_loss: 2.4368 - val_acc: 0.4600\n",
      "Epoch 45/50\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 0.1870 - acc: 0.9631 - val_loss: 2.5063 - val_acc: 0.4770\n",
      "Epoch 46/50\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 0.1746 - acc: 0.9663 - val_loss: 2.4970 - val_acc: 0.4830\n",
      "Epoch 47/50\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.1559 - acc: 0.9718 - val_loss: 2.5636 - val_acc: 0.4530\n",
      "Epoch 48/50\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 0.1495 - acc: 0.9737 - val_loss: 2.6500 - val_acc: 0.4470\n",
      "Epoch 49/50\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 0.1396 - acc: 0.9780 - val_loss: 2.6314 - val_acc: 0.4720\n",
      "Epoch 50/50\n",
      "5997/5997 [==============================] - 0s 20us/step - loss: 0.1256 - acc: 0.9818 - val_loss: 2.6579 - val_acc: 0.4510\n"
     ]
    }
   ],
   "source": [
    "baseline_model_val = baseline_model.fit(X_train, \n",
    "                                        y_train_lab, \n",
    "                                         epochs=50,\n",
    "                    batch_size=128,\n",
    "                                        validation_data=(X_val,y_val_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the history attribute and store the dictionary\n",
    "baseline_model_val_dict = baseline_model_val.history\n",
    "\n",
    "# Print the keys\n",
    "\n",
    "baseline_model_val_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5997/5997 [==============================] - 0s 31us/step\n",
      "----------\n",
      "Training Loss: 0.104 \n",
      "Training Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "results_train = baseline_model.evaluate(X_train, y_train_lab)\n",
    "print('----------')\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 33us/step\n",
      "----------\n",
      "Test Loss: 2.91 \n",
      "Test Accuracy: 0.443\n"
     ]
    }
   ],
   "source": [
    "results_test = baseline_model.evaluate(X_test, y_test_lab)\n",
    "print('----------')\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "loss_values = baseline_model_val_dict['loss']\n",
    "val_loss_values = baseline_model_val_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "ax.plot(epochs, loss_values, label='Training loss')\n",
    "ax.plot(epochs, val_loss_values, label='Validation loss')\n",
    "\n",
    "ax.set_title('Training & validation loss')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "acc_values = baseline_model_val_dict['acc'] \n",
    "val_acc_values = baseline_model_val_dict['val_acc']\n",
    "\n",
    "ax.plot(epochs, acc_values, label='Training acc')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc')\n",
    "ax.set_title('Training & validation accuracy')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = models.Sequential()\n",
    "model_2.add(layers.Dense(256, activation='relu', input_shape=(29,)))\n",
    "model_2.add(layers.Dense(128, activation='relu'))\n",
    "model_2.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "model_2.compile(optimizer='nadam', \n",
    "                loss='categorical_crossentropy', \n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'filepath'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-293-74a99d8270c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Define the callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m early_stopping = [EarlyStopping(monitor='val_loss', patience=10), \n\u001b[0;32m----> 6\u001b[0;31m                   ModelCheckpoint( monitor='val_loss', save_best_only=True)]\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'filepath'"
     ]
    }
   ],
   "source": [
    "# Import EarlyStopping and ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Define the callbacks\n",
    "early_stopping = [EarlyStopping(monitor='val_loss', patience=10), \n",
    "                  ModelCheckpoint( monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5997 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "5997/5997 [==============================] - 1s 92us/step - loss: 1.7093 - acc: 0.3608 - val_loss: 1.6275 - val_acc: 0.4000\n",
      "Epoch 2/50\n",
      "5997/5997 [==============================] - 0s 41us/step - loss: 1.5296 - acc: 0.4521 - val_loss: 1.5874 - val_acc: 0.4290\n",
      "Epoch 3/50\n",
      "5997/5997 [==============================] - 0s 41us/step - loss: 1.4619 - acc: 0.4736 - val_loss: 1.5495 - val_acc: 0.4600\n",
      "Epoch 4/50\n",
      "5997/5997 [==============================] - 0s 41us/step - loss: 1.4117 - acc: 0.4942 - val_loss: 1.5384 - val_acc: 0.4670\n",
      "Epoch 5/50\n",
      "5997/5997 [==============================] - 0s 41us/step - loss: 1.3688 - acc: 0.5083 - val_loss: 1.5318 - val_acc: 0.4690\n",
      "Epoch 6/50\n",
      "5997/5997 [==============================] - 0s 42us/step - loss: 1.3309 - acc: 0.5239 - val_loss: 1.5291 - val_acc: 0.4500\n",
      "Epoch 7/50\n",
      "5997/5997 [==============================] - 0s 41us/step - loss: 1.2927 - acc: 0.5403 - val_loss: 1.5640 - val_acc: 0.4480\n",
      "Epoch 8/50\n",
      "5997/5997 [==============================] - 0s 40us/step - loss: 1.2581 - acc: 0.5568 - val_loss: 1.5399 - val_acc: 0.4610\n",
      "Epoch 9/50\n",
      "5997/5997 [==============================] - 0s 41us/step - loss: 1.2234 - acc: 0.5644 - val_loss: 1.5396 - val_acc: 0.4570\n",
      "Epoch 10/50\n",
      "5997/5997 [==============================] - 0s 41us/step - loss: 1.1889 - acc: 0.5733 - val_loss: 1.5564 - val_acc: 0.4770\n",
      "Epoch 11/50\n",
      "5997/5997 [==============================] - 0s 42us/step - loss: 1.1606 - acc: 0.5901 - val_loss: 1.5419 - val_acc: 0.4710\n",
      "Epoch 12/50\n",
      "5997/5997 [==============================] - 0s 41us/step - loss: 1.1221 - acc: 0.6005 - val_loss: 1.5758 - val_acc: 0.4540\n",
      "Epoch 13/50\n",
      "5997/5997 [==============================] - 0s 41us/step - loss: 1.0922 - acc: 0.6106 - val_loss: 1.5582 - val_acc: 0.4670\n",
      "Epoch 14/50\n",
      "5997/5997 [==============================] - 0s 41us/step - loss: 1.0595 - acc: 0.6195 - val_loss: 1.6137 - val_acc: 0.4750\n",
      "Epoch 15/50\n",
      "5997/5997 [==============================] - 0s 42us/step - loss: 1.0318 - acc: 0.6378 - val_loss: 1.6187 - val_acc: 0.4650\n",
      "Epoch 16/50\n",
      "5997/5997 [==============================] - 0s 42us/step - loss: 1.0003 - acc: 0.6395 - val_loss: 1.6120 - val_acc: 0.4740\n"
     ]
    }
   ],
   "source": [
    "model_2_val = model_2.fit(X_train, \n",
    "                          y_train_lb, \n",
    "                          epochs=50, \n",
    "                          callbacks=early_stopping ,\n",
    "                         validation_data=(X_val,y_val_lb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5997/5997 [==============================] - 0s 17us/step\n",
      "Training Loss: 0.921 \n",
      "Training Accuracy: 0.682\n",
      "----------\n",
      "1000/1000 [==============================] - 0s 22us/step\n",
      "Test Loss: 1.61 \n",
      "Test Accuracy: 0.469\n"
     ]
    }
   ],
   "source": [
    "results_train = model_2.evaluate(X_train, y_train_lb)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = model_2.evaluate(X_test, y_test_lb)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5997 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "5997/5997 [==============================] - 1s 183us/step - loss: 2.5648 - acc: 0.3705 - val_loss: 2.1455 - val_acc: 0.4350\n",
      "Epoch 2/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 2.0130 - acc: 0.4344 - val_loss: 1.8478 - val_acc: 0.4590\n",
      "Epoch 3/30\n",
      "5997/5997 [==============================] - 0s 20us/step - loss: 1.8012 - acc: 0.4529 - val_loss: 1.7124 - val_acc: 0.4430\n",
      "Epoch 4/30\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 1.7051 - acc: 0.4672 - val_loss: 1.6562 - val_acc: 0.4640\n",
      "Epoch 5/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.6490 - acc: 0.4637 - val_loss: 1.6218 - val_acc: 0.4540\n",
      "Epoch 6/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.6165 - acc: 0.4801 - val_loss: 1.6090 - val_acc: 0.4550\n",
      "Epoch 7/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.5960 - acc: 0.4831 - val_loss: 1.5919 - val_acc: 0.4570\n",
      "Epoch 8/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.5772 - acc: 0.4876 - val_loss: 1.5812 - val_acc: 0.4600\n",
      "Epoch 9/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.5665 - acc: 0.4871 - val_loss: 1.5791 - val_acc: 0.4490\n",
      "Epoch 10/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.5568 - acc: 0.4932 - val_loss: 1.5893 - val_acc: 0.4660\n",
      "Epoch 11/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.5448 - acc: 0.4989 - val_loss: 1.5742 - val_acc: 0.4710\n",
      "Epoch 12/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.5315 - acc: 0.5044 - val_loss: 1.5612 - val_acc: 0.4700\n",
      "Epoch 13/30\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 1.5267 - acc: 0.5069 - val_loss: 1.5888 - val_acc: 0.4620\n",
      "Epoch 14/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.5227 - acc: 0.5086 - val_loss: 1.5800 - val_acc: 0.4660\n",
      "Epoch 15/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.5130 - acc: 0.5103 - val_loss: 1.5727 - val_acc: 0.4770\n",
      "Epoch 16/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.5120 - acc: 0.5113 - val_loss: 1.5486 - val_acc: 0.4840\n",
      "Epoch 17/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.5006 - acc: 0.5169 - val_loss: 1.5869 - val_acc: 0.4660\n",
      "Epoch 18/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.4911 - acc: 0.5231 - val_loss: 1.5645 - val_acc: 0.4670\n",
      "Epoch 19/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.4874 - acc: 0.5164 - val_loss: 1.5626 - val_acc: 0.4870\n",
      "Epoch 20/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.4860 - acc: 0.5241 - val_loss: 1.5608 - val_acc: 0.4760\n",
      "Epoch 21/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.4749 - acc: 0.5289 - val_loss: 1.5754 - val_acc: 0.4930\n",
      "Epoch 22/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.4748 - acc: 0.5256 - val_loss: 1.5536 - val_acc: 0.4940\n",
      "Epoch 23/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.4657 - acc: 0.5373 - val_loss: 1.5504 - val_acc: 0.5010\n",
      "Epoch 24/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.4669 - acc: 0.5396 - val_loss: 1.5428 - val_acc: 0.5040\n",
      "Epoch 25/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.4587 - acc: 0.5439 - val_loss: 1.5663 - val_acc: 0.4830\n",
      "Epoch 26/30\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 1.4430 - acc: 0.5484 - val_loss: 1.6198 - val_acc: 0.4750\n",
      "Epoch 27/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.4439 - acc: 0.5443 - val_loss: 1.5855 - val_acc: 0.4870\n",
      "Epoch 28/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.4466 - acc: 0.5474 - val_loss: 1.5692 - val_acc: 0.4690\n",
      "Epoch 29/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.4376 - acc: 0.5568 - val_loss: 1.5881 - val_acc: 0.4620\n",
      "Epoch 30/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.4298 - acc: 0.5566 - val_loss: 1.5726 - val_acc: 0.4920\n"
     ]
    }
   ],
   "source": [
    "# Import regularizers\n",
    "from keras import regularizers\n",
    "L2_model = models.Sequential()\n",
    "\n",
    "# Add the input and first hidden layer\n",
    "L2_model.add(layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.005), input_shape=(29,)))\n",
    "\n",
    "# Add another hidden layer\n",
    "L2_model.add(layers.Dense(128, kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "\n",
    "# Add an output layer\n",
    "L2_model.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L2_model.compile(optimizer='nadam', \n",
    "                 loss='sparse_categorical_crossentropy', \n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "L2_model_val = L2_model.fit(X_train, \n",
    "                            y_train_lab, \n",
    "                              epochs=30,\n",
    "                    batch_size=128 ,\n",
    "                            validation_data=(X_val,y_val_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5997/5997 [==============================] - 0s 33us/step\n",
      "Training Loss: 1.39 \n",
      "Training Accuracy: 0.571\n",
      "----------\n",
      "1000/1000 [==============================] - 0s 30us/step\n",
      "Test Loss: 1.64 \n",
      "Test Accuracy: 0.486\n"
     ]
    }
   ],
   "source": [
    "results_train = L2_model.evaluate(X_train, y_train_lab)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = L2_model.evaluate(X_test, y_test_lab)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (50,) and (30,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-299-66a3d10319df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL2_acc_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training acc (L2)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL2_val_acc_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation acc (L2)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline_model_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training acc (Baseline)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1664\u001b[0m         \"\"\"\n\u001b[1;32m   1665\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1666\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1667\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 270\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (50,) and (30,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# L2 model details\n",
    "L2_model_dict = L2_model_val.history\n",
    "L2_acc_values = L2_model_dict['acc'] \n",
    "L2_val_acc_values = L2_model_dict['val_acc']\n",
    "\n",
    "# Baseline model\n",
    "baseline_model_acc = baseline_model_val_dict['acc'] \n",
    "baseline_model_val_acc = baseline_model_val_dict['val_acc']\n",
    "\n",
    "# Plot the accuracy for these models\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, L2_acc_values, label='Training acc (L2)')\n",
    "ax.plot(epochs, L2_val_acc_values, label='Validation acc (L2)')\n",
    "ax.plot(epochs, baseline_model_acc, label='Training acc (Baseline)')\n",
    "ax.plot(epochs, baseline_model_val_acc, label='Validation acc (Baseline)')\n",
    "ax.set_title('Training & validation accuracy L2 vs regular')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5997 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "5997/5997 [==============================] - 1s 185us/step - loss: 8.9392 - acc: 0.3025 - val_loss: 3.9812 - val_acc: 0.3740\n",
      "Epoch 2/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 2.5724 - acc: 0.3517 - val_loss: 2.0542 - val_acc: 0.3720\n",
      "Epoch 3/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 2.0222 - acc: 0.3625 - val_loss: 1.9582 - val_acc: 0.3710\n",
      "Epoch 4/30\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 1.9672 - acc: 0.3702 - val_loss: 1.9296 - val_acc: 0.3800\n",
      "Epoch 5/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.9412 - acc: 0.3782 - val_loss: 1.9002 - val_acc: 0.3940\n",
      "Epoch 6/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.9213 - acc: 0.3849 - val_loss: 1.8818 - val_acc: 0.4020\n",
      "Epoch 7/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.9016 - acc: 0.3929 - val_loss: 1.8695 - val_acc: 0.3890\n",
      "Epoch 8/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.8859 - acc: 0.3975 - val_loss: 1.8504 - val_acc: 0.4050\n",
      "Epoch 9/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.8717 - acc: 0.3980 - val_loss: 1.8435 - val_acc: 0.4040\n",
      "Epoch 10/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.8628 - acc: 0.4049 - val_loss: 1.8195 - val_acc: 0.4180\n",
      "Epoch 11/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.8499 - acc: 0.4095 - val_loss: 1.8121 - val_acc: 0.4210\n",
      "Epoch 12/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.8405 - acc: 0.4125 - val_loss: 1.7990 - val_acc: 0.4130\n",
      "Epoch 13/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.8343 - acc: 0.4135 - val_loss: 1.7956 - val_acc: 0.4300\n",
      "Epoch 14/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.8278 - acc: 0.4245 - val_loss: 1.7852 - val_acc: 0.4270\n",
      "Epoch 15/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.8245 - acc: 0.4220 - val_loss: 1.7781 - val_acc: 0.4300\n",
      "Epoch 16/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.8177 - acc: 0.4225 - val_loss: 1.7803 - val_acc: 0.4320\n",
      "Epoch 17/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.8136 - acc: 0.4214 - val_loss: 1.7774 - val_acc: 0.4200\n",
      "Epoch 18/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.8114 - acc: 0.4235 - val_loss: 1.7760 - val_acc: 0.4270\n",
      "Epoch 19/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.8077 - acc: 0.4232 - val_loss: 1.7622 - val_acc: 0.4340\n",
      "Epoch 20/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.8051 - acc: 0.4255 - val_loss: 1.7682 - val_acc: 0.4330\n",
      "Epoch 21/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.8014 - acc: 0.4324 - val_loss: 1.7655 - val_acc: 0.4250\n",
      "Epoch 22/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.8004 - acc: 0.4229 - val_loss: 1.7631 - val_acc: 0.4320\n",
      "Epoch 23/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.7964 - acc: 0.4274 - val_loss: 1.7574 - val_acc: 0.4390\n",
      "Epoch 24/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.7928 - acc: 0.4284 - val_loss: 1.7664 - val_acc: 0.4340\n",
      "Epoch 25/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.7912 - acc: 0.4272 - val_loss: 1.7488 - val_acc: 0.4320\n",
      "Epoch 26/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.7883 - acc: 0.4287 - val_loss: 1.7568 - val_acc: 0.4290\n",
      "Epoch 27/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.7878 - acc: 0.4279 - val_loss: 1.7473 - val_acc: 0.4310\n",
      "Epoch 28/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 1.7838 - acc: 0.4282 - val_loss: 1.7470 - val_acc: 0.4340\n",
      "Epoch 29/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.7818 - acc: 0.4280 - val_loss: 1.7439 - val_acc: 0.4460\n",
      "Epoch 30/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.7802 - acc: 0.4324 - val_loss: 1.7445 - val_acc: 0.4350\n"
     ]
    }
   ],
   "source": [
    "L1_model = models.Sequential()\n",
    "\n",
    "# Add the input and first hidden layer\n",
    "L1_model.add(layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l1(0.005), input_shape=(29,)))\n",
    "\n",
    "# Add a hidden layer\n",
    "L1_model.add(layers.Dense(128, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "\n",
    "# Add an output layer\n",
    "L1_model.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L1_model.compile(optimizer='nadam', \n",
    "                 loss='sparse_categorical_crossentropy', \n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "L1_model_val = L1_model.fit(X_train, \n",
    "                            y_train_lab, \n",
    "                             epochs=30,\n",
    "                    batch_size=128 ,\n",
    "                            validation_data=(X_val,y_val_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "L1_model_dict = L1_model_val.history\n",
    "\n",
    "acc_values = L1_model_dict['acc'] \n",
    "val_acc_values = L1_model_dict['val_acc']\n",
    "\n",
    "epochs = range(1, len(acc_values) + 1)\n",
    "ax.plot(epochs, acc_values, label='Training acc L1')\n",
    "ax.plot(epochs, val_acc_values, label='Validation acc L1')\n",
    "ax.set_title('Training & validation accuracy with L1 regularization')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5997/5997 [==============================] - 0s 36us/step\n",
      "Training Loss: 1.77 \n",
      "Training Accuracy: 0.442\n",
      "----------\n",
      "1000/1000 [==============================] - 0s 32us/step\n",
      "Test Loss: 1.8 \n",
      "Test Accuracy: 0.425\n"
     ]
    }
   ],
   "source": [
    "results_train = L1_model.evaluate(X_train, y_train_lab)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = L1_model.evaluate(X_test, y_test_lab)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5997 samples, validate on 1000 samples\n",
      "Epoch 1/70\n",
      "5997/5997 [==============================] - 1s 219us/step - loss: 4.3452 - acc: 0.3317 - val_loss: 2.0157 - val_acc: 0.3480\n",
      "Epoch 2/70\n",
      "5997/5997 [==============================] - 0s 54us/step - loss: 1.9635 - acc: 0.3722 - val_loss: 1.9166 - val_acc: 0.3890\n",
      "Epoch 3/70\n",
      "5997/5997 [==============================] - 0s 52us/step - loss: 1.9082 - acc: 0.3850 - val_loss: 1.8929 - val_acc: 0.4000\n",
      "Epoch 4/70\n",
      "5997/5997 [==============================] - 0s 53us/step - loss: 1.8835 - acc: 0.3959 - val_loss: 1.8392 - val_acc: 0.4140\n",
      "Epoch 5/70\n",
      "5997/5997 [==============================] - 0s 52us/step - loss: 1.8627 - acc: 0.3982 - val_loss: 1.8364 - val_acc: 0.4130\n",
      "Epoch 6/70\n",
      "5997/5997 [==============================] - 0s 53us/step - loss: 1.8499 - acc: 0.4074 - val_loss: 1.8055 - val_acc: 0.4290\n",
      "Epoch 7/70\n",
      "5997/5997 [==============================] - 0s 54us/step - loss: 1.8338 - acc: 0.4097 - val_loss: 1.7916 - val_acc: 0.4320\n",
      "Epoch 8/70\n",
      "5997/5997 [==============================] - 0s 52us/step - loss: 1.8228 - acc: 0.4115 - val_loss: 1.7960 - val_acc: 0.4190\n",
      "Epoch 9/70\n",
      "5997/5997 [==============================] - 0s 52us/step - loss: 1.8135 - acc: 0.4177 - val_loss: 1.7765 - val_acc: 0.4260\n",
      "Epoch 10/70\n",
      "5997/5997 [==============================] - 0s 52us/step - loss: 1.8037 - acc: 0.4197 - val_loss: 1.7743 - val_acc: 0.4410\n",
      "Epoch 11/70\n",
      "5997/5997 [==============================] - 0s 52us/step - loss: 1.7976 - acc: 0.4202 - val_loss: 1.7675 - val_acc: 0.4280\n",
      "Epoch 12/70\n",
      "5997/5997 [==============================] - 0s 50us/step - loss: 1.7899 - acc: 0.4284 - val_loss: 1.7593 - val_acc: 0.4380\n",
      "Epoch 13/70\n",
      "5997/5997 [==============================] - 0s 51us/step - loss: 1.7827 - acc: 0.4284 - val_loss: 1.7503 - val_acc: 0.4360\n",
      "Epoch 14/70\n",
      "5997/5997 [==============================] - 0s 52us/step - loss: 1.7764 - acc: 0.4302 - val_loss: 1.7420 - val_acc: 0.4480\n",
      "Epoch 15/70\n",
      "5997/5997 [==============================] - 0s 50us/step - loss: 1.7716 - acc: 0.4309 - val_loss: 1.7391 - val_acc: 0.4370\n",
      "Epoch 16/70\n",
      "5997/5997 [==============================] - 0s 51us/step - loss: 1.7676 - acc: 0.4351 - val_loss: 1.7444 - val_acc: 0.4440\n",
      "Epoch 17/70\n",
      "5997/5997 [==============================] - 0s 52us/step - loss: 1.7619 - acc: 0.4330 - val_loss: 1.7463 - val_acc: 0.4310\n",
      "Epoch 18/70\n",
      "5997/5997 [==============================] - 0s 50us/step - loss: 1.7617 - acc: 0.4391 - val_loss: 1.7384 - val_acc: 0.4340\n",
      "Epoch 19/70\n",
      "5997/5997 [==============================] - 0s 52us/step - loss: 1.7550 - acc: 0.4411 - val_loss: 1.7286 - val_acc: 0.4400\n",
      "Epoch 20/70\n",
      "5997/5997 [==============================] - 0s 61us/step - loss: 1.7503 - acc: 0.4424 - val_loss: 1.7370 - val_acc: 0.4290\n",
      "Epoch 21/70\n",
      "5997/5997 [==============================] - 0s 62us/step - loss: 1.7488 - acc: 0.4401 - val_loss: 1.7175 - val_acc: 0.4510\n",
      "Epoch 22/70\n",
      "5997/5997 [==============================] - 0s 58us/step - loss: 1.7449 - acc: 0.4434 - val_loss: 1.7179 - val_acc: 0.4480\n",
      "Epoch 23/70\n",
      "5997/5997 [==============================] - 0s 56us/step - loss: 1.7423 - acc: 0.4431 - val_loss: 1.7175 - val_acc: 0.4440\n",
      "Epoch 24/70\n",
      "5997/5997 [==============================] - 0s 57us/step - loss: 1.7392 - acc: 0.4424 - val_loss: 1.7061 - val_acc: 0.4530\n",
      "Epoch 25/70\n",
      "5997/5997 [==============================] - 0s 51us/step - loss: 1.7360 - acc: 0.4427 - val_loss: 1.7123 - val_acc: 0.4510\n",
      "Epoch 26/70\n",
      "5997/5997 [==============================] - 0s 51us/step - loss: 1.7362 - acc: 0.4452 - val_loss: 1.7150 - val_acc: 0.4340\n",
      "Epoch 27/70\n",
      "5997/5997 [==============================] - 0s 53us/step - loss: 1.7293 - acc: 0.4426 - val_loss: 1.7119 - val_acc: 0.4470\n",
      "Epoch 28/70\n",
      "5997/5997 [==============================] - 0s 53us/step - loss: 1.7314 - acc: 0.4424 - val_loss: 1.7084 - val_acc: 0.4330\n",
      "Epoch 29/70\n",
      "5824/5997 [============================>.] - ETA: 0s - loss: 1.7294 - acc: 0.4449"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-304-0b421360a915>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                             \u001b[0my_train_lab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                             validation_data=(X_val,y_val_lab))\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "L1_model2 = models.Sequential()\n",
    "\n",
    "# Add the input and first hidden layer\n",
    "L1_model2.add(layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l1(0.005), input_shape=(29,)))\n",
    "\n",
    "# Add a hidden layer\n",
    "L1_model2.add(layers.Dense(128, kernel_regularizer=regularizers.l1(0.005), activation='relu'))\n",
    "\n",
    "# Add an output layer\n",
    "L1_model2.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "L1_model2.compile(optimizer='nadam', \n",
    "                 loss='sparse_categorical_crossentropy', \n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Train the model \n",
    "L1_model2_val = L1_model2.fit(X_train, \n",
    "                            y_train_lab, \n",
    "                            epochs=70, \n",
    "                            validation_data=(X_val,y_val_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5997/5997 [==============================] - 1s 167us/step\n",
      "Training Loss: 1.71 \n",
      "Training Accuracy: 0.447\n",
      "----------\n",
      "1000/1000 [==============================] - 0s 33us/step\n",
      "Test Loss: 1.75 \n",
      "Test Accuracy: 0.445\n"
     ]
    }
   ],
   "source": [
    "results_train = L1_model2.evaluate(X_train, y_train_lab)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = L1_model2.evaluate(X_test, y_test_lab)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5997 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "5997/5997 [==============================] - 1s 219us/step - loss: 1.8803 - acc: 0.2956 - val_loss: 1.6433 - val_acc: 0.4110\n",
      "Epoch 2/30\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.7578 - acc: 0.3445 - val_loss: 1.5931 - val_acc: 0.4070\n",
      "Epoch 3/30\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.7304 - acc: 0.3648 - val_loss: 1.5814 - val_acc: 0.4190\n",
      "Epoch 4/30\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.7049 - acc: 0.3744 - val_loss: 1.5663 - val_acc: 0.4320\n",
      "Epoch 5/30\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.6872 - acc: 0.3890 - val_loss: 1.5373 - val_acc: 0.4230\n",
      "Epoch 6/30\n",
      "5997/5997 [==============================] - 0s 23us/step - loss: 1.6644 - acc: 0.3890 - val_loss: 1.5346 - val_acc: 0.4270\n",
      "Epoch 7/30\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.6804 - acc: 0.3800 - val_loss: 1.5359 - val_acc: 0.4310\n",
      "Epoch 8/30\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.6513 - acc: 0.3897 - val_loss: 1.5316 - val_acc: 0.4380\n",
      "Epoch 9/30\n",
      "5997/5997 [==============================] - 0s 22us/step - loss: 1.6553 - acc: 0.3867 - val_loss: 1.5156 - val_acc: 0.4400\n",
      "Epoch 10/30\n",
      "5997/5997 [==============================] - 0s 22us/step - loss: 1.6427 - acc: 0.3955 - val_loss: 1.5074 - val_acc: 0.4460\n",
      "Epoch 11/30\n",
      "5997/5997 [==============================] - 0s 22us/step - loss: 1.6454 - acc: 0.3979 - val_loss: 1.5164 - val_acc: 0.4310\n",
      "Epoch 12/30\n",
      "5997/5997 [==============================] - 0s 21us/step - loss: 1.6269 - acc: 0.4060 - val_loss: 1.5092 - val_acc: 0.4340\n",
      "Epoch 13/30\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.6404 - acc: 0.4029 - val_loss: 1.4998 - val_acc: 0.4430\n",
      "Epoch 14/30\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.6239 - acc: 0.4155 - val_loss: 1.4963 - val_acc: 0.4440\n",
      "Epoch 15/30\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.6251 - acc: 0.3950 - val_loss: 1.5064 - val_acc: 0.4490\n",
      "Epoch 16/30\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.6384 - acc: 0.3969 - val_loss: 1.5053 - val_acc: 0.4490\n",
      "Epoch 17/30\n",
      "5997/5997 [==============================] - 0s 23us/step - loss: 1.6225 - acc: 0.4082 - val_loss: 1.4843 - val_acc: 0.4580\n",
      "Epoch 18/30\n",
      "5997/5997 [==============================] - 0s 23us/step - loss: 1.6058 - acc: 0.4174 - val_loss: 1.4889 - val_acc: 0.4500\n",
      "Epoch 19/30\n",
      "5997/5997 [==============================] - 0s 26us/step - loss: 1.6215 - acc: 0.4107 - val_loss: 1.4998 - val_acc: 0.4450\n",
      "Epoch 20/30\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.6000 - acc: 0.4169 - val_loss: 1.5042 - val_acc: 0.4540\n",
      "Epoch 21/30\n",
      "5997/5997 [==============================] - 0s 22us/step - loss: 1.5896 - acc: 0.4182 - val_loss: 1.4798 - val_acc: 0.4490\n",
      "Epoch 22/30\n",
      "5997/5997 [==============================] - 0s 22us/step - loss: 1.6070 - acc: 0.4120 - val_loss: 1.4968 - val_acc: 0.4340\n",
      "Epoch 23/30\n",
      "5997/5997 [==============================] - 0s 23us/step - loss: 1.5937 - acc: 0.4164 - val_loss: 1.4809 - val_acc: 0.4580\n",
      "Epoch 24/30\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.5861 - acc: 0.4180 - val_loss: 1.4851 - val_acc: 0.4530\n",
      "Epoch 25/30\n",
      "5997/5997 [==============================] - 0s 23us/step - loss: 1.6042 - acc: 0.4132 - val_loss: 1.4866 - val_acc: 0.4560\n",
      "Epoch 26/30\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.5996 - acc: 0.4105 - val_loss: 1.4791 - val_acc: 0.4530\n",
      "Epoch 27/30\n",
      "5997/5997 [==============================] - 0s 21us/step - loss: 1.5942 - acc: 0.4177 - val_loss: 1.4921 - val_acc: 0.4500\n",
      "Epoch 28/30\n",
      "5997/5997 [==============================] - 0s 21us/step - loss: 1.5827 - acc: 0.4192 - val_loss: 1.4777 - val_acc: 0.4480\n",
      "Epoch 29/30\n",
      "5997/5997 [==============================] - 0s 22us/step - loss: 1.5794 - acc: 0.4242 - val_loss: 1.4781 - val_acc: 0.4540\n",
      "Epoch 30/30\n",
      "5997/5997 [==============================] - 0s 22us/step - loss: 1.5821 - acc: 0.4202 - val_loss: 1.4766 - val_acc: 0.4660\n"
     ]
    }
   ],
   "source": [
    "dropout_model = models.Sequential()\n",
    "\n",
    "# Implement dropout to the input layer\n",
    "# NOTE: This is where you define the number of units in the input layer\n",
    "dropout_model.add(layers.Dropout(0.3, input_shape=(29,)))\n",
    "\n",
    "# Add the first hidden layer\n",
    "dropout_model.add(layers.Dense(256, activation='relu'))\n",
    "\n",
    "# Implement dropout to the first hidden layer \n",
    "dropout_model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Add the second hidden layer\n",
    "dropout_model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "# Implement dropout to the second hidden layer \n",
    "dropout_model.add(layers.Dropout(0.4))\n",
    "\n",
    "# Add the output layer\n",
    "dropout_model.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "dropout_model.compile(optimizer='nadam', \n",
    "                      loss='sparse_categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "dropout_model_val = dropout_model.fit(X_train, \n",
    "                                      y_train_lab, \n",
    "                                      epochs=30,\n",
    "                    batch_size=128,\n",
    "                                      validation_data=(X_val, y_val_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5997/5997 [==============================] - 0s 30us/step\n",
      "Training Loss: 1.41 \n",
      "Training Accuracy: 0.491\n",
      "----------\n",
      "1000/1000 [==============================] - 0s 32us/step\n",
      "Test Loss: 1.55 \n",
      "Test Accuracy: 0.441\n"
     ]
    }
   ],
   "source": [
    "results_train = dropout_model.evaluate(X_train, y_train_lab)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = dropout_model.evaluate(X_test, y_test_lab)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5997 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "5997/5997 [==============================] - 1s 210us/step - loss: 5.5494 - acc: 0.2048 - val_loss: 2.1762 - val_acc: 0.2700\n",
      "Epoch 2/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 2.2063 - acc: 0.2478 - val_loss: 2.1948 - val_acc: 0.2340\n",
      "Epoch 3/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 2.1063 - acc: 0.2386 - val_loss: 2.1546 - val_acc: 0.2670\n",
      "Epoch 4/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 2.1377 - acc: 0.2036 - val_loss: 2.1382 - val_acc: 0.1760\n",
      "Epoch 5/30\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 2.1405 - acc: 0.1723 - val_loss: 2.2625 - val_acc: 0.1780\n",
      "Epoch 6/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 2.1933 - acc: 0.1714 - val_loss: 2.1748 - val_acc: 0.1740\n",
      "Epoch 7/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 2.1381 - acc: 0.1637 - val_loss: 2.0403 - val_acc: 0.1700\n",
      "Epoch 8/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 2.1002 - acc: 0.1806 - val_loss: 2.0718 - val_acc: 0.1810\n",
      "Epoch 9/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 2.0742 - acc: 0.1763 - val_loss: 2.1071 - val_acc: 0.1820\n",
      "Epoch 10/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 2.0906 - acc: 0.1758 - val_loss: 2.1049 - val_acc: 0.1740\n",
      "Epoch 11/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 2.0970 - acc: 0.1773 - val_loss: 2.1903 - val_acc: 0.1970\n",
      "Epoch 12/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 2.0947 - acc: 0.1949 - val_loss: 2.1546 - val_acc: 0.1860\n",
      "Epoch 13/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 2.0769 - acc: 0.1641 - val_loss: 2.1644 - val_acc: 0.1570\n",
      "Epoch 14/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 2.0810 - acc: 0.1582 - val_loss: 2.2111 - val_acc: 0.1570\n",
      "Epoch 15/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 2.0902 - acc: 0.1576 - val_loss: 2.3063 - val_acc: 0.1560\n",
      "Epoch 16/30\n",
      "5997/5997 [==============================] - 0s 16us/step - loss: 2.1126 - acc: 0.1594 - val_loss: 2.1562 - val_acc: 0.1590\n",
      "Epoch 17/30\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 2.1020 - acc: 0.1597 - val_loss: 2.1423 - val_acc: 0.1570\n",
      "Epoch 18/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 2.0976 - acc: 0.1651 - val_loss: 2.1625 - val_acc: 0.1690\n",
      "Epoch 19/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 2.1050 - acc: 0.1728 - val_loss: 2.1977 - val_acc: 0.2190\n",
      "Epoch 20/30\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 2.0984 - acc: 0.2031 - val_loss: 2.1951 - val_acc: 0.2100\n",
      "Epoch 21/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 2.0986 - acc: 0.2028 - val_loss: 2.2033 - val_acc: 0.2100\n",
      "Epoch 22/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 2.1068 - acc: 0.2043 - val_loss: 2.1663 - val_acc: 0.2070\n",
      "Epoch 23/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 2.1263 - acc: 0.1958 - val_loss: 2.1520 - val_acc: 0.2070\n",
      "Epoch 24/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 2.1249 - acc: 0.1949 - val_loss: 2.1818 - val_acc: 0.2030\n",
      "Epoch 25/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 2.1257 - acc: 0.1948 - val_loss: 2.1537 - val_acc: 0.2020\n",
      "Epoch 26/30\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 2.1273 - acc: 0.1939 - val_loss: 2.1828 - val_acc: 0.2010\n",
      "Epoch 27/30\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 2.1223 - acc: 0.1944 - val_loss: 2.1809 - val_acc: 0.2010\n",
      "Epoch 28/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 2.1171 - acc: 0.1939 - val_loss: 2.1965 - val_acc: 0.2010\n",
      "Epoch 29/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 2.1128 - acc: 0.1896 - val_loss: 2.0891 - val_acc: 0.1890\n",
      "Epoch 30/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 2.2084 - acc: 0.1793 - val_loss: 2.2181 - val_acc: 0.1700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x151cbfac8>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_model = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "he_model.add(layers.Dense(256, kernel_initializer='he_normal', activation='relu', input_shape=(29,)))\n",
    "\n",
    "# Add another hidden layer\n",
    "he_model.add(layers.Dense(128, kernel_initializer='he_normal',activation='relu'))\n",
    "\n",
    "# Add an output layer\n",
    "he_model.add(layers.Dense(8, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "he_model.compile(optimizer='nadam', \n",
    "                      loss='sparse_categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "he_model.fit(X_train,  y_train_lab, epochs=30,\n",
    "                    batch_size=128, validation_data=(X_val, y_val_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5997 samples, validate on 1000 samples\n",
      "Epoch 1/30\n",
      "5997/5997 [==============================] - 1s 218us/step - loss: 1.7042 - acc: 0.3717 - val_loss: 1.5105 - val_acc: 0.4440\n",
      "Epoch 2/30\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 1.5126 - acc: 0.4606 - val_loss: 1.4797 - val_acc: 0.4620\n",
      "Epoch 3/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 1.4329 - acc: 0.4839 - val_loss: 1.4613 - val_acc: 0.4750\n",
      "Epoch 4/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.3622 - acc: 0.5103 - val_loss: 1.4342 - val_acc: 0.4810\n",
      "Epoch 5/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.3082 - acc: 0.5316 - val_loss: 1.4485 - val_acc: 0.4880\n",
      "Epoch 6/30\n",
      "5997/5997 [==============================] - 0s 20us/step - loss: 1.2546 - acc: 0.5499 - val_loss: 1.4683 - val_acc: 0.4680\n",
      "Epoch 7/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.2022 - acc: 0.5768 - val_loss: 1.4299 - val_acc: 0.4950\n",
      "Epoch 8/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 1.1537 - acc: 0.5891 - val_loss: 1.4399 - val_acc: 0.4800\n",
      "Epoch 9/30\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 1.0994 - acc: 0.6151 - val_loss: 1.4593 - val_acc: 0.4740\n",
      "Epoch 10/30\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 1.0584 - acc: 0.6283 - val_loss: 1.4730 - val_acc: 0.4900\n",
      "Epoch 11/30\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 1.0057 - acc: 0.6498 - val_loss: 1.4699 - val_acc: 0.4800\n",
      "Epoch 12/30\n",
      "5997/5997 [==============================] - 0s 17us/step - loss: 0.9631 - acc: 0.6695 - val_loss: 1.4535 - val_acc: 0.5100\n",
      "Epoch 13/30\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 0.9217 - acc: 0.6843 - val_loss: 1.4693 - val_acc: 0.5110\n",
      "Epoch 14/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.8848 - acc: 0.7034 - val_loss: 1.5459 - val_acc: 0.4780\n",
      "Epoch 15/30\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 0.8345 - acc: 0.7219 - val_loss: 1.5427 - val_acc: 0.4870\n",
      "Epoch 16/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.8030 - acc: 0.7319 - val_loss: 1.5732 - val_acc: 0.4970\n",
      "Epoch 17/30\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 0.7650 - acc: 0.7492 - val_loss: 1.6607 - val_acc: 0.4640\n",
      "Epoch 18/30\n",
      "5997/5997 [==============================] - 0s 20us/step - loss: 0.7234 - acc: 0.7592 - val_loss: 1.6014 - val_acc: 0.5020\n",
      "Epoch 19/30\n",
      "5997/5997 [==============================] - 0s 20us/step - loss: 0.6929 - acc: 0.7734 - val_loss: 1.6423 - val_acc: 0.4780\n",
      "Epoch 20/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.6498 - acc: 0.7917 - val_loss: 1.6741 - val_acc: 0.4830\n",
      "Epoch 21/30\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 0.6161 - acc: 0.8031 - val_loss: 1.7094 - val_acc: 0.4930\n",
      "Epoch 22/30\n",
      "5997/5997 [==============================] - 0s 20us/step - loss: 0.5781 - acc: 0.8194 - val_loss: 1.7773 - val_acc: 0.4820\n",
      "Epoch 23/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.5548 - acc: 0.8301 - val_loss: 1.8157 - val_acc: 0.4650\n",
      "Epoch 24/30\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 0.5212 - acc: 0.8383 - val_loss: 1.7853 - val_acc: 0.5040\n",
      "Epoch 25/30\n",
      "5997/5997 [==============================] - 0s 18us/step - loss: 0.4938 - acc: 0.8473 - val_loss: 1.8496 - val_acc: 0.4740\n",
      "Epoch 26/30\n",
      "5997/5997 [==============================] - 0s 19us/step - loss: 0.4743 - acc: 0.8504 - val_loss: 1.8808 - val_acc: 0.4730\n",
      "Epoch 27/30\n",
      "5997/5997 [==============================] - 0s 20us/step - loss: 0.4281 - acc: 0.8768 - val_loss: 1.9232 - val_acc: 0.4740\n",
      "Epoch 28/30\n",
      "5997/5997 [==============================] - 0s 20us/step - loss: 0.4019 - acc: 0.8863 - val_loss: 1.9415 - val_acc: 0.4920\n",
      "Epoch 29/30\n",
      "5997/5997 [==============================] - 0s 20us/step - loss: 0.3768 - acc: 0.8948 - val_loss: 1.9832 - val_acc: 0.4830\n",
      "Epoch 30/30\n",
      "5997/5997 [==============================] - 0s 20us/step - loss: 0.3529 - acc: 0.9063 - val_loss: 2.0129 - val_acc: 0.4800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14b7e3780>"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lecun_model = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "lecun_model.add(layers.Dense(256, kernel_initializer='lecun_normal', activation='relu', input_shape=(29,)))\n",
    "\n",
    "# Add another hidden layer\n",
    "lecun_model.add(layers.Dense(128, activation='relu'))\n",
    "\n",
    "# Add alen output layer\n",
    "lecun_model.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "lecun_model.compile(optimizer='nadam', \n",
    "                      loss='sparse_categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "lecun_model.fit(X_train,  y_train_lab,  epochs=30,\n",
    "                    batch_size=128, validation_data=(X_val, y_val_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5997/5997 [==============================] - 0s 35us/step\n",
      "1000/1000 [==============================] - 0s 30us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.29574206748743426, 0.9306319826679348], [2.202577857971191, 0.455])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lecun_model.evaluate(X_train, y_train_lab),lecun_model.evaluate(X_test, y_test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5997 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "5997/5997 [==============================] - 2s 270us/step - loss: 2.6870 - acc: 0.2905 - val_loss: 2.2499 - val_acc: 0.4180\n",
      "Epoch 2/50\n",
      "5997/5997 [==============================] - 0s 26us/step - loss: 2.2428 - acc: 0.3762 - val_loss: 1.9955 - val_acc: 0.4430\n",
      "Epoch 3/50\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 2.0155 - acc: 0.4077 - val_loss: 1.8324 - val_acc: 0.4180\n",
      "Epoch 4/50\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.8813 - acc: 0.4205 - val_loss: 1.7425 - val_acc: 0.4380\n",
      "Epoch 5/50\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.7802 - acc: 0.4337 - val_loss: 1.6729 - val_acc: 0.4610\n",
      "Epoch 6/50\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.7341 - acc: 0.4382 - val_loss: 1.6213 - val_acc: 0.4540\n",
      "Epoch 7/50\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.6794 - acc: 0.4447 - val_loss: 1.5865 - val_acc: 0.4590\n",
      "Epoch 8/50\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.6368 - acc: 0.4559 - val_loss: 1.5874 - val_acc: 0.4740\n",
      "Epoch 9/50\n",
      "5997/5997 [==============================] - 0s 23us/step - loss: 1.6259 - acc: 0.4566 - val_loss: 1.5528 - val_acc: 0.4570\n",
      "Epoch 10/50\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.6046 - acc: 0.4582 - val_loss: 1.5480 - val_acc: 0.4670\n",
      "Epoch 11/50\n",
      "5997/5997 [==============================] - 0s 23us/step - loss: 1.5854 - acc: 0.4664 - val_loss: 1.5216 - val_acc: 0.4790\n",
      "Epoch 12/50\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.5615 - acc: 0.4761 - val_loss: 1.5282 - val_acc: 0.4650\n",
      "Epoch 13/50\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.5588 - acc: 0.4776 - val_loss: 1.5226 - val_acc: 0.4810\n",
      "Epoch 14/50\n",
      "5997/5997 [==============================] - 0s 23us/step - loss: 1.5527 - acc: 0.4769 - val_loss: 1.5185 - val_acc: 0.4890\n",
      "Epoch 15/50\n",
      "5997/5997 [==============================] - 0s 26us/step - loss: 1.5442 - acc: 0.4762 - val_loss: 1.5180 - val_acc: 0.4840\n",
      "Epoch 16/50\n",
      "5997/5997 [==============================] - 0s 26us/step - loss: 1.5418 - acc: 0.4777 - val_loss: 1.5099 - val_acc: 0.4800\n",
      "Epoch 17/50\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.5277 - acc: 0.4912 - val_loss: 1.5038 - val_acc: 0.4720\n",
      "Epoch 18/50\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.5130 - acc: 0.4932 - val_loss: 1.4987 - val_acc: 0.4830\n",
      "Epoch 19/50\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.5155 - acc: 0.4832 - val_loss: 1.4960 - val_acc: 0.5060\n",
      "Epoch 20/50\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.5099 - acc: 0.5013 - val_loss: 1.4835 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "5997/5997 [==============================] - 0s 26us/step - loss: 1.5005 - acc: 0.4991 - val_loss: 1.4914 - val_acc: 0.5020\n",
      "Epoch 22/50\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.4894 - acc: 0.5048 - val_loss: 1.4982 - val_acc: 0.5040\n",
      "Epoch 23/50\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.4844 - acc: 0.5086 - val_loss: 1.4887 - val_acc: 0.4990\n",
      "Epoch 24/50\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.4779 - acc: 0.5033 - val_loss: 1.4982 - val_acc: 0.4850\n",
      "Epoch 25/50\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.4741 - acc: 0.5073 - val_loss: 1.4836 - val_acc: 0.5010\n",
      "Epoch 26/50\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.4809 - acc: 0.5083 - val_loss: 1.4805 - val_acc: 0.4880\n",
      "Epoch 27/50\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.4651 - acc: 0.5139 - val_loss: 1.4921 - val_acc: 0.4970\n",
      "Epoch 28/50\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.4660 - acc: 0.5111 - val_loss: 1.4816 - val_acc: 0.4940\n",
      "Epoch 29/50\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.4529 - acc: 0.5138 - val_loss: 1.4763 - val_acc: 0.5050\n",
      "Epoch 30/50\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.4554 - acc: 0.5156 - val_loss: 1.4787 - val_acc: 0.5100\n",
      "Epoch 31/50\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.4521 - acc: 0.5166 - val_loss: 1.4916 - val_acc: 0.4980\n",
      "Epoch 32/50\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.4445 - acc: 0.5244 - val_loss: 1.4831 - val_acc: 0.5130\n",
      "Epoch 33/50\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.4365 - acc: 0.5258 - val_loss: 1.4794 - val_acc: 0.4950\n",
      "Epoch 34/50\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.4307 - acc: 0.5308 - val_loss: 1.4631 - val_acc: 0.5040\n",
      "Epoch 35/50\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.4249 - acc: 0.5264 - val_loss: 1.4831 - val_acc: 0.5110\n",
      "Epoch 36/50\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.4398 - acc: 0.5289 - val_loss: 1.4880 - val_acc: 0.5060\n",
      "Epoch 37/50\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.4294 - acc: 0.5293 - val_loss: 1.4811 - val_acc: 0.5060\n",
      "Epoch 38/50\n",
      "5997/5997 [==============================] - 0s 26us/step - loss: 1.4229 - acc: 0.5323 - val_loss: 1.4649 - val_acc: 0.5130\n",
      "Epoch 39/50\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.4230 - acc: 0.5428 - val_loss: 1.4746 - val_acc: 0.5110\n",
      "Epoch 40/50\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.4128 - acc: 0.5341 - val_loss: 1.4742 - val_acc: 0.5020\n",
      "Epoch 41/50\n",
      "5997/5997 [==============================] - 0s 27us/step - loss: 1.4170 - acc: 0.5353 - val_loss: 1.4732 - val_acc: 0.5080\n",
      "Epoch 42/50\n",
      "5997/5997 [==============================] - 0s 23us/step - loss: 1.4172 - acc: 0.5334 - val_loss: 1.4625 - val_acc: 0.5140\n",
      "Epoch 43/50\n",
      "5997/5997 [==============================] - 0s 23us/step - loss: 1.4052 - acc: 0.5349 - val_loss: 1.4631 - val_acc: 0.5270\n",
      "Epoch 44/50\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.4012 - acc: 0.5398 - val_loss: 1.4651 - val_acc: 0.5190\n",
      "Epoch 45/50\n",
      "5997/5997 [==============================] - 0s 23us/step - loss: 1.3939 - acc: 0.5454 - val_loss: 1.4751 - val_acc: 0.5090\n",
      "Epoch 46/50\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.3950 - acc: 0.5428 - val_loss: 1.4770 - val_acc: 0.5140\n",
      "Epoch 47/50\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.3896 - acc: 0.5473 - val_loss: 1.4772 - val_acc: 0.5090\n",
      "Epoch 48/50\n",
      "5997/5997 [==============================] - 0s 27us/step - loss: 1.3979 - acc: 0.5441 - val_loss: 1.4708 - val_acc: 0.5100\n",
      "Epoch 49/50\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.3859 - acc: 0.5514 - val_loss: 1.4706 - val_acc: 0.5120\n",
      "Epoch 50/50\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.3845 - acc: 0.5506 - val_loss: 1.4731 - val_acc: 0.5230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15612db70>"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lecun_model = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "lecun_model.add(layers.Dense(256, kernel_initializer='lecun_normal',activation='relu', input_shape=(29,)))\n",
    "lecun_model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Add another hidden layer\n",
    "lecun_model.add(layers.Dense(128,kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "lecun_model.add(layers.Dropout(0.4))\n",
    "\n",
    "\n",
    "# Add an output layer\n",
    "lecun_model.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "lecun_model.compile(optimizer='nadam', \n",
    "                      loss='sparse_categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "lecun_model.fit(X_train,  y_train_lab, epochs=50,\n",
    "                    batch_size=128, validation_data=(X_val, y_val_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5997/5997 [==============================] - 0s 39us/step\n",
      "Training Loss: 1.22 \n",
      "Training Accuracy: 0.63\n",
      "----------\n",
      "1000/1000 [==============================] - 0s 36us/step\n",
      "Test Loss: 1.56 \n",
      "Test Accuracy: 0.496\n"
     ]
    }
   ],
   "source": [
    "results_train = lecun_model.evaluate(X_train, y_train_lab)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = lecun_model.evaluate(X_test, y_test_lab)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5997 samples, validate on 1000 samples\n",
      "Epoch 1/75\n",
      "5997/5997 [==============================] - 2s 335us/step - loss: 3.0061 - acc: 0.2541 - val_loss: 2.5121 - val_acc: 0.4010\n",
      "Epoch 2/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 2.4319 - acc: 0.3560 - val_loss: 2.1328 - val_acc: 0.4220\n",
      "Epoch 3/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 2.1488 - acc: 0.3885 - val_loss: 1.9246 - val_acc: 0.4300\n",
      "Epoch 4/75\n",
      "5997/5997 [==============================] - 0s 29us/step - loss: 1.9738 - acc: 0.4044 - val_loss: 1.7897 - val_acc: 0.4440\n",
      "Epoch 5/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.8631 - acc: 0.4104 - val_loss: 1.7161 - val_acc: 0.4470\n",
      "Epoch 6/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.7951 - acc: 0.4269 - val_loss: 1.6779 - val_acc: 0.4460\n",
      "Epoch 7/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.7489 - acc: 0.4304 - val_loss: 1.6285 - val_acc: 0.4680\n",
      "Epoch 8/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.7016 - acc: 0.4414 - val_loss: 1.5931 - val_acc: 0.4600\n",
      "Epoch 9/75\n",
      "5997/5997 [==============================] - 0s 29us/step - loss: 1.6863 - acc: 0.4456 - val_loss: 1.6003 - val_acc: 0.4510\n",
      "Epoch 10/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.6691 - acc: 0.4519 - val_loss: 1.5700 - val_acc: 0.4670\n",
      "Epoch 11/75\n",
      "5997/5997 [==============================] - 0s 33us/step - loss: 1.6533 - acc: 0.4519 - val_loss: 1.5653 - val_acc: 0.4660\n",
      "Epoch 12/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.6427 - acc: 0.4597 - val_loss: 1.5852 - val_acc: 0.4640\n",
      "Epoch 13/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.6283 - acc: 0.4631 - val_loss: 1.5425 - val_acc: 0.4680\n",
      "Epoch 14/75\n",
      "5997/5997 [==============================] - 0s 29us/step - loss: 1.6107 - acc: 0.4697 - val_loss: 1.5587 - val_acc: 0.4660\n",
      "Epoch 15/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.6161 - acc: 0.4756 - val_loss: 1.5462 - val_acc: 0.4660\n",
      "Epoch 16/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.6134 - acc: 0.4571 - val_loss: 1.5449 - val_acc: 0.4740\n",
      "Epoch 17/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5989 - acc: 0.4767 - val_loss: 1.5560 - val_acc: 0.4740\n",
      "Epoch 18/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.5892 - acc: 0.4771 - val_loss: 1.5408 - val_acc: 0.4730\n",
      "Epoch 19/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.5800 - acc: 0.4839 - val_loss: 1.5296 - val_acc: 0.4850\n",
      "Epoch 20/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5905 - acc: 0.4781 - val_loss: 1.5413 - val_acc: 0.4780\n",
      "Epoch 21/75\n",
      "5997/5997 [==============================] - 0s 28us/step - loss: 1.5848 - acc: 0.4829 - val_loss: 1.5185 - val_acc: 0.4720\n",
      "Epoch 22/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.5681 - acc: 0.4869 - val_loss: 1.5150 - val_acc: 0.4930\n",
      "Epoch 23/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.5718 - acc: 0.4849 - val_loss: 1.5131 - val_acc: 0.4830\n",
      "Epoch 24/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.5628 - acc: 0.4886 - val_loss: 1.5179 - val_acc: 0.4890\n",
      "Epoch 25/75\n",
      "5997/5997 [==============================] - 0s 33us/step - loss: 1.5577 - acc: 0.4986 - val_loss: 1.5212 - val_acc: 0.4930\n",
      "Epoch 26/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.5537 - acc: 0.4956 - val_loss: 1.5057 - val_acc: 0.4920\n",
      "Epoch 27/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.5474 - acc: 0.4926 - val_loss: 1.5432 - val_acc: 0.4780\n",
      "Epoch 28/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5529 - acc: 0.5011 - val_loss: 1.5101 - val_acc: 0.4920\n",
      "Epoch 29/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.5435 - acc: 0.5124 - val_loss: 1.5121 - val_acc: 0.4930\n",
      "Epoch 30/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.5345 - acc: 0.5009 - val_loss: 1.5250 - val_acc: 0.4920\n",
      "Epoch 31/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.5420 - acc: 0.5083 - val_loss: 1.5036 - val_acc: 0.4950\n",
      "Epoch 32/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5372 - acc: 0.5058 - val_loss: 1.5208 - val_acc: 0.4920\n",
      "Epoch 33/75\n",
      "5997/5997 [==============================] - 0s 33us/step - loss: 1.5271 - acc: 0.5111 - val_loss: 1.5153 - val_acc: 0.4960\n",
      "Epoch 34/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5235 - acc: 0.5124 - val_loss: 1.5073 - val_acc: 0.4920\n",
      "Epoch 35/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.5185 - acc: 0.5091 - val_loss: 1.5180 - val_acc: 0.5010\n",
      "Epoch 36/75\n",
      "5997/5997 [==============================] - 0s 33us/step - loss: 1.5237 - acc: 0.5114 - val_loss: 1.5147 - val_acc: 0.4980\n",
      "Epoch 37/75\n",
      "5997/5997 [==============================] - 0s 33us/step - loss: 1.5151 - acc: 0.5189 - val_loss: 1.5087 - val_acc: 0.4920\n",
      "Epoch 38/75\n",
      "5997/5997 [==============================] - 0s 37us/step - loss: 1.5080 - acc: 0.5124 - val_loss: 1.4960 - val_acc: 0.4960\n",
      "Epoch 39/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.5058 - acc: 0.5144 - val_loss: 1.5082 - val_acc: 0.5120\n",
      "Epoch 40/75\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.5143 - acc: 0.5194 - val_loss: 1.5020 - val_acc: 0.5100\n",
      "Epoch 41/75\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.4948 - acc: 0.5241 - val_loss: 1.5117 - val_acc: 0.5020\n",
      "Epoch 42/75\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.4820 - acc: 0.5298 - val_loss: 1.5136 - val_acc: 0.5080\n",
      "Epoch 43/75\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.4904 - acc: 0.5269 - val_loss: 1.5075 - val_acc: 0.5010\n",
      "Epoch 44/75\n",
      "5997/5997 [==============================] - 0s 25us/step - loss: 1.4946 - acc: 0.5239 - val_loss: 1.5144 - val_acc: 0.5060\n",
      "Epoch 45/75\n",
      "5997/5997 [==============================] - 0s 27us/step - loss: 1.5001 - acc: 0.5248 - val_loss: 1.5045 - val_acc: 0.5190\n",
      "Epoch 46/75\n",
      "5997/5997 [==============================] - 0s 29us/step - loss: 1.4809 - acc: 0.5338 - val_loss: 1.5149 - val_acc: 0.5070\n",
      "Epoch 47/75\n",
      "5997/5997 [==============================] - 0s 29us/step - loss: 1.4918 - acc: 0.5309 - val_loss: 1.5086 - val_acc: 0.5070\n",
      "Epoch 48/75\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.4822 - acc: 0.5319 - val_loss: 1.5077 - val_acc: 0.5150\n",
      "Epoch 49/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4682 - acc: 0.5401 - val_loss: 1.5172 - val_acc: 0.5050\n",
      "Epoch 50/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4773 - acc: 0.5281 - val_loss: 1.5293 - val_acc: 0.4980\n",
      "Epoch 51/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.4803 - acc: 0.5318 - val_loss: 1.5099 - val_acc: 0.5140\n",
      "Epoch 52/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4728 - acc: 0.5418 - val_loss: 1.5161 - val_acc: 0.5010\n",
      "Epoch 53/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4639 - acc: 0.5443 - val_loss: 1.4944 - val_acc: 0.5060\n",
      "Epoch 54/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.4652 - acc: 0.5308 - val_loss: 1.5148 - val_acc: 0.5130\n",
      "Epoch 55/75\n",
      "5997/5997 [==============================] - 0s 34us/step - loss: 1.4582 - acc: 0.5479 - val_loss: 1.5242 - val_acc: 0.5030\n",
      "Epoch 56/75\n",
      "5997/5997 [==============================] - 0s 34us/step - loss: 1.4617 - acc: 0.5426 - val_loss: 1.5073 - val_acc: 0.5030\n",
      "Epoch 57/75\n",
      "5997/5997 [==============================] - 0s 29us/step - loss: 1.4396 - acc: 0.5519 - val_loss: 1.4995 - val_acc: 0.5080\n",
      "Epoch 58/75\n",
      "5997/5997 [==============================] - 0s 23us/step - loss: 1.4451 - acc: 0.5458 - val_loss: 1.5329 - val_acc: 0.5030\n",
      "Epoch 59/75\n",
      "5997/5997 [==============================] - 0s 24us/step - loss: 1.4394 - acc: 0.5549 - val_loss: 1.5069 - val_acc: 0.5090\n",
      "Epoch 60/75\n",
      "5997/5997 [==============================] - 0s 26us/step - loss: 1.4467 - acc: 0.5424 - val_loss: 1.5062 - val_acc: 0.5170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4335 - acc: 0.5534 - val_loss: 1.5147 - val_acc: 0.5080\n",
      "Epoch 62/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4325 - acc: 0.5601 - val_loss: 1.5264 - val_acc: 0.5100\n",
      "Epoch 63/75\n",
      "5997/5997 [==============================] - 0s 35us/step - loss: 1.4379 - acc: 0.5536 - val_loss: 1.5208 - val_acc: 0.5080\n",
      "Epoch 64/75\n",
      "5997/5997 [==============================] - 0s 29us/step - loss: 1.4308 - acc: 0.5599 - val_loss: 1.5265 - val_acc: 0.5190\n",
      "Epoch 65/75\n",
      "5997/5997 [==============================] - 0s 27us/step - loss: 1.4292 - acc: 0.5586 - val_loss: 1.5234 - val_acc: 0.5110\n",
      "Epoch 66/75\n",
      "5997/5997 [==============================] - 0s 28us/step - loss: 1.4341 - acc: 0.5491 - val_loss: 1.5188 - val_acc: 0.5130\n",
      "Epoch 67/75\n",
      "5997/5997 [==============================] - 0s 29us/step - loss: 1.4343 - acc: 0.5583 - val_loss: 1.5207 - val_acc: 0.5030\n",
      "Epoch 68/75\n",
      "5997/5997 [==============================] - 0s 28us/step - loss: 1.4343 - acc: 0.5628 - val_loss: 1.5242 - val_acc: 0.5150\n",
      "Epoch 69/75\n",
      "5997/5997 [==============================] - 0s 28us/step - loss: 1.4277 - acc: 0.5546 - val_loss: 1.5119 - val_acc: 0.5160\n",
      "Epoch 70/75\n",
      "5997/5997 [==============================] - 0s 28us/step - loss: 1.4207 - acc: 0.5569 - val_loss: 1.5115 - val_acc: 0.5250\n",
      "Epoch 71/75\n",
      "5997/5997 [==============================] - 0s 28us/step - loss: 1.4253 - acc: 0.5586 - val_loss: 1.5154 - val_acc: 0.5160\n",
      "Epoch 72/75\n",
      "5997/5997 [==============================] - 0s 28us/step - loss: 1.4273 - acc: 0.5649 - val_loss: 1.5122 - val_acc: 0.5190\n",
      "Epoch 73/75\n",
      "5997/5997 [==============================] - 0s 29us/step - loss: 1.4138 - acc: 0.5675 - val_loss: 1.5123 - val_acc: 0.5320\n",
      "Epoch 74/75\n",
      "5997/5997 [==============================] - 0s 29us/step - loss: 1.4144 - acc: 0.5686 - val_loss: 1.5136 - val_acc: 0.5170\n",
      "Epoch 75/75\n",
      "5997/5997 [==============================] - 0s 28us/step - loss: 1.4178 - acc: 0.5653 - val_loss: 1.5118 - val_acc: 0.5240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159cb34a8>"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lecun_model = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "lecun_model.add(layers.Dense(256, kernel_initializer='lecun_normal',activation='relu', input_shape=(29,)))\n",
    "lecun_model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Add another hidden layer\n",
    "lecun_model.add(layers.Dense(128,kernel_initializer='lecun_normal',kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "lecun_model.add(layers.Dropout(0.4))\n",
    "\n",
    "lecun_model.add(layers.Dense(128,kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "lecun_model.add(layers.Dropout(0.4))\n",
    "\n",
    "# Add an output layer\n",
    "lecun_model.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "lecun_model.compile(optimizer='nadam', \n",
    "                      loss='sparse_categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "lecun_model.fit(X_train,  y_train_lab, epochs=75,\n",
    "                    batch_size=128, validation_data=(X_val, y_val_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5997/5997 [==============================] - 0s 38us/step\n",
      "Training Loss: 1.22 \n",
      "Training Accuracy: 0.649\n",
      "----------\n",
      "1000/1000 [==============================] - 0s 42us/step\n",
      "Test Loss: 1.58 \n",
      "Test Accuracy: 0.508\n"
     ]
    }
   ],
   "source": [
    "results_train = lecun_model.evaluate(X_train, y_train_lab)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = lecun_model.evaluate(X_test, y_test_lab)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5997 samples, validate on 1000 samples\n",
      "Epoch 1/75\n",
      "5997/5997 [==============================] - 2s 385us/step - loss: 2.9934 - acc: 0.2771 - val_loss: 2.3631 - val_acc: 0.4160\n",
      "Epoch 2/75\n",
      "5997/5997 [==============================] - 0s 79us/step - loss: 2.2604 - acc: 0.3630 - val_loss: 1.9572 - val_acc: 0.4090\n",
      "Epoch 3/75\n",
      "5997/5997 [==============================] - 0s 79us/step - loss: 1.9673 - acc: 0.3867 - val_loss: 1.7839 - val_acc: 0.4460\n",
      "Epoch 4/75\n",
      "5997/5997 [==============================] - 0s 81us/step - loss: 1.8438 - acc: 0.4069 - val_loss: 1.7040 - val_acc: 0.4580\n",
      "Epoch 5/75\n",
      "5997/5997 [==============================] - 0s 80us/step - loss: 1.7926 - acc: 0.4042 - val_loss: 1.6618 - val_acc: 0.4460\n",
      "Epoch 6/75\n",
      "5997/5997 [==============================] - 0s 79us/step - loss: 1.7552 - acc: 0.4287 - val_loss: 1.6930 - val_acc: 0.4390\n",
      "Epoch 7/75\n",
      "5997/5997 [==============================] - 0s 78us/step - loss: 1.7377 - acc: 0.4270 - val_loss: 1.6297 - val_acc: 0.4380\n",
      "Epoch 8/75\n",
      "5997/5997 [==============================] - 0s 81us/step - loss: 1.7252 - acc: 0.4351 - val_loss: 1.6131 - val_acc: 0.4480\n",
      "Epoch 9/75\n",
      "5997/5997 [==============================] - 0s 79us/step - loss: 1.7203 - acc: 0.4322 - val_loss: 1.6155 - val_acc: 0.4500\n",
      "Epoch 10/75\n",
      "5997/5997 [==============================] - 0s 83us/step - loss: 1.7117 - acc: 0.4347 - val_loss: 1.6191 - val_acc: 0.4550\n",
      "Epoch 11/75\n",
      "5997/5997 [==============================] - 0s 81us/step - loss: 1.6919 - acc: 0.4494 - val_loss: 1.6103 - val_acc: 0.4690\n",
      "Epoch 12/75\n",
      "5997/5997 [==============================] - 0s 81us/step - loss: 1.6833 - acc: 0.4471 - val_loss: 1.5847 - val_acc: 0.4650\n",
      "Epoch 13/75\n",
      "5997/5997 [==============================] - 0s 81us/step - loss: 1.6709 - acc: 0.4519 - val_loss: 1.5781 - val_acc: 0.4800\n",
      "Epoch 14/75\n",
      "5997/5997 [==============================] - 0s 81us/step - loss: 1.6899 - acc: 0.4501 - val_loss: 1.5972 - val_acc: 0.4670\n",
      "Epoch 15/75\n",
      "5997/5997 [==============================] - 0s 79us/step - loss: 1.6714 - acc: 0.4607 - val_loss: 1.5950 - val_acc: 0.4670\n",
      "Epoch 16/75\n",
      "5997/5997 [==============================] - 0s 78us/step - loss: 1.6645 - acc: 0.4611 - val_loss: 1.5981 - val_acc: 0.4580\n",
      "Epoch 17/75\n",
      "5997/5997 [==============================] - 0s 79us/step - loss: 1.6622 - acc: 0.4574 - val_loss: 1.5970 - val_acc: 0.4610\n",
      "Epoch 18/75\n",
      "5997/5997 [==============================] - 0s 80us/step - loss: 1.6563 - acc: 0.4636 - val_loss: 1.6010 - val_acc: 0.4660\n",
      "Epoch 19/75\n",
      "5997/5997 [==============================] - 0s 80us/step - loss: 1.6496 - acc: 0.4644 - val_loss: 1.5866 - val_acc: 0.4970\n",
      "Epoch 20/75\n",
      "5997/5997 [==============================] - 0s 79us/step - loss: 1.6548 - acc: 0.4692 - val_loss: 1.6090 - val_acc: 0.4650\n",
      "Epoch 21/75\n",
      "5997/5997 [==============================] - 0s 79us/step - loss: 1.6466 - acc: 0.4717 - val_loss: 1.5815 - val_acc: 0.4790\n",
      "Epoch 22/75\n",
      "5997/5997 [==============================] - 0s 79us/step - loss: 1.6365 - acc: 0.4819 - val_loss: 1.5707 - val_acc: 0.4780\n",
      "Epoch 23/75\n",
      "5997/5997 [==============================] - 0s 80us/step - loss: 1.6439 - acc: 0.4744 - val_loss: 1.5682 - val_acc: 0.4730\n",
      "Epoch 24/75\n",
      "5997/5997 [==============================] - 0s 79us/step - loss: 1.6340 - acc: 0.4724 - val_loss: 1.5593 - val_acc: 0.4860\n",
      "Epoch 25/75\n",
      "5997/5997 [==============================] - 0s 79us/step - loss: 1.6376 - acc: 0.4817 - val_loss: 1.5751 - val_acc: 0.4750\n",
      "Epoch 26/75\n",
      "5997/5997 [==============================] - 0s 79us/step - loss: 1.6362 - acc: 0.4772 - val_loss: 1.5679 - val_acc: 0.4790\n",
      "Epoch 27/75\n",
      "5997/5997 [==============================] - 0s 81us/step - loss: 1.6281 - acc: 0.4777 - val_loss: 1.5768 - val_acc: 0.4810\n",
      "Epoch 28/75\n",
      "5997/5997 [==============================] - 0s 80us/step - loss: 1.6249 - acc: 0.4822 - val_loss: 1.5667 - val_acc: 0.4760\n",
      "Epoch 29/75\n",
      "5997/5997 [==============================] - 0s 80us/step - loss: 1.6188 - acc: 0.4874 - val_loss: 1.5771 - val_acc: 0.4670\n",
      "Epoch 30/75\n",
      "5997/5997 [==============================] - 0s 80us/step - loss: 1.6136 - acc: 0.4937 - val_loss: 1.5511 - val_acc: 0.4780\n",
      "Epoch 31/75\n",
      "5997/5997 [==============================] - 0s 82us/step - loss: 1.6119 - acc: 0.4876 - val_loss: 1.5791 - val_acc: 0.4930\n",
      "Epoch 32/75\n",
      "5997/5997 [==============================] - 0s 80us/step - loss: 1.6010 - acc: 0.4982 - val_loss: 1.5539 - val_acc: 0.4960\n",
      "Epoch 33/75\n",
      "5997/5997 [==============================] - 0s 81us/step - loss: 1.6075 - acc: 0.4871 - val_loss: 1.5680 - val_acc: 0.4800\n",
      "Epoch 34/75\n",
      "5997/5997 [==============================] - 0s 79us/step - loss: 1.5890 - acc: 0.5059 - val_loss: 1.5754 - val_acc: 0.4860\n",
      "Epoch 35/75\n",
      "5997/5997 [==============================] - 0s 81us/step - loss: 1.5914 - acc: 0.4956 - val_loss: 1.5671 - val_acc: 0.4770\n",
      "Epoch 36/75\n",
      "5997/5997 [==============================] - 0s 80us/step - loss: 1.5927 - acc: 0.5046 - val_loss: 1.5678 - val_acc: 0.4810\n",
      "Epoch 37/75\n",
      "5997/5997 [==============================] - 0s 82us/step - loss: 1.5857 - acc: 0.5049 - val_loss: 1.5850 - val_acc: 0.4850\n",
      "Epoch 38/75\n",
      "5997/5997 [==============================] - 0s 83us/step - loss: 1.5950 - acc: 0.5013 - val_loss: 1.5570 - val_acc: 0.4880\n",
      "Epoch 39/75\n",
      "5997/5997 [==============================] - 0s 82us/step - loss: 1.5915 - acc: 0.4977 - val_loss: 1.5736 - val_acc: 0.4860\n",
      "Epoch 40/75\n",
      "5997/5997 [==============================] - 1s 89us/step - loss: 1.5949 - acc: 0.4989 - val_loss: 1.5602 - val_acc: 0.4910\n",
      "Epoch 41/75\n",
      "5997/5997 [==============================] - 1s 88us/step - loss: 1.5764 - acc: 0.5044 - val_loss: 1.5702 - val_acc: 0.4710\n",
      "Epoch 42/75\n",
      "5997/5997 [==============================] - 1s 90us/step - loss: 1.5926 - acc: 0.5001 - val_loss: 1.5867 - val_acc: 0.4730\n",
      "Epoch 43/75\n",
      "5997/5997 [==============================] - 1s 91us/step - loss: 1.5813 - acc: 0.4986 - val_loss: 1.5572 - val_acc: 0.5000\n",
      "Epoch 44/75\n",
      "5997/5997 [==============================] - 1s 90us/step - loss: 1.5871 - acc: 0.4944 - val_loss: 1.5617 - val_acc: 0.4990\n",
      "Epoch 45/75\n",
      "5997/5997 [==============================] - 1s 88us/step - loss: 1.5737 - acc: 0.5094 - val_loss: 1.5620 - val_acc: 0.4960\n",
      "Epoch 46/75\n",
      "5997/5997 [==============================] - 0s 83us/step - loss: 1.5813 - acc: 0.5063 - val_loss: 1.5521 - val_acc: 0.4870\n",
      "Epoch 47/75\n",
      "5997/5997 [==============================] - 0s 79us/step - loss: 1.5803 - acc: 0.5036 - val_loss: 1.5627 - val_acc: 0.4960\n",
      "Epoch 48/75\n",
      "5997/5997 [==============================] - 0s 79us/step - loss: 1.5796 - acc: 0.5133 - val_loss: 1.5682 - val_acc: 0.4840\n",
      "Epoch 49/75\n",
      "5997/5997 [==============================] - 1s 92us/step - loss: 1.5730 - acc: 0.5124 - val_loss: 1.5498 - val_acc: 0.4980\n",
      "Epoch 50/75\n",
      "5997/5997 [==============================] - 1s 87us/step - loss: 1.5699 - acc: 0.5089 - val_loss: 1.5818 - val_acc: 0.4850\n",
      "Epoch 51/75\n",
      "5997/5997 [==============================] - 1s 85us/step - loss: 1.5697 - acc: 0.5103 - val_loss: 1.5560 - val_acc: 0.4990\n",
      "Epoch 52/75\n",
      "5997/5997 [==============================] - 0s 79us/step - loss: 1.5667 - acc: 0.5129 - val_loss: 1.5504 - val_acc: 0.5010\n",
      "Epoch 53/75\n",
      "5997/5997 [==============================] - 1s 85us/step - loss: 1.5592 - acc: 0.5229 - val_loss: 1.5643 - val_acc: 0.4890\n",
      "Epoch 54/75\n",
      "5997/5997 [==============================] - 1s 91us/step - loss: 1.5551 - acc: 0.5216 - val_loss: 1.5694 - val_acc: 0.4980\n",
      "Epoch 55/75\n",
      "5997/5997 [==============================] - 1s 94us/step - loss: 1.5571 - acc: 0.5213 - val_loss: 1.5440 - val_acc: 0.5080\n",
      "Epoch 56/75\n",
      "5997/5997 [==============================] - 1s 94us/step - loss: 1.5611 - acc: 0.5178 - val_loss: 1.5802 - val_acc: 0.4950\n",
      "Epoch 57/75\n",
      "5997/5997 [==============================] - 1s 95us/step - loss: 1.5526 - acc: 0.5289 - val_loss: 1.5500 - val_acc: 0.5000\n",
      "Epoch 58/75\n",
      "5997/5997 [==============================] - 1s 95us/step - loss: 1.5628 - acc: 0.5119 - val_loss: 1.5623 - val_acc: 0.4880\n",
      "Epoch 59/75\n",
      "5997/5997 [==============================] - 1s 91us/step - loss: 1.5477 - acc: 0.5314 - val_loss: 1.5708 - val_acc: 0.4880\n",
      "Epoch 60/75\n",
      "5997/5997 [==============================] - 1s 90us/step - loss: 1.5488 - acc: 0.5178 - val_loss: 1.5618 - val_acc: 0.5100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/75\n",
      "5997/5997 [==============================] - 1s 89us/step - loss: 1.5519 - acc: 0.5274 - val_loss: 1.5498 - val_acc: 0.5100\n",
      "Epoch 62/75\n",
      "5997/5997 [==============================] - 1s 89us/step - loss: 1.5564 - acc: 0.5213 - val_loss: 1.5658 - val_acc: 0.5100\n",
      "Epoch 63/75\n",
      "5997/5997 [==============================] - 0s 80us/step - loss: 1.5430 - acc: 0.5228 - val_loss: 1.5504 - val_acc: 0.4960\n",
      "Epoch 64/75\n",
      "5997/5997 [==============================] - 0s 82us/step - loss: 1.5563 - acc: 0.5244 - val_loss: 1.5797 - val_acc: 0.4950\n",
      "Epoch 65/75\n",
      "5997/5997 [==============================] - 0s 81us/step - loss: 1.5527 - acc: 0.5214 - val_loss: 1.5577 - val_acc: 0.5050\n",
      "Epoch 66/75\n",
      "5997/5997 [==============================] - 1s 91us/step - loss: 1.5330 - acc: 0.5339 - val_loss: 1.5733 - val_acc: 0.4980\n",
      "Epoch 67/75\n",
      "5997/5997 [==============================] - 1s 95us/step - loss: 1.5358 - acc: 0.5313 - val_loss: 1.5481 - val_acc: 0.5160\n",
      "Epoch 68/75\n",
      "5997/5997 [==============================] - 1s 96us/step - loss: 1.5395 - acc: 0.5274 - val_loss: 1.5602 - val_acc: 0.5030\n",
      "Epoch 69/75\n",
      "5997/5997 [==============================] - 1s 90us/step - loss: 1.5479 - acc: 0.5236 - val_loss: 1.5642 - val_acc: 0.4970\n",
      "Epoch 70/75\n",
      "5997/5997 [==============================] - 1s 91us/step - loss: 1.5446 - acc: 0.5259 - val_loss: 1.5824 - val_acc: 0.4950\n",
      "Epoch 71/75\n",
      "5997/5997 [==============================] - 1s 95us/step - loss: 1.5399 - acc: 0.5298 - val_loss: 1.5515 - val_acc: 0.5050\n",
      "Epoch 72/75\n",
      "5997/5997 [==============================] - 1s 97us/step - loss: 1.5409 - acc: 0.5243 - val_loss: 1.5701 - val_acc: 0.5060\n",
      "Epoch 73/75\n",
      "5997/5997 [==============================] - 1s 89us/step - loss: 1.5393 - acc: 0.5323 - val_loss: 1.5750 - val_acc: 0.5070\n",
      "Epoch 74/75\n",
      "5997/5997 [==============================] - 1s 87us/step - loss: 1.5391 - acc: 0.5319 - val_loss: 1.5530 - val_acc: 0.5020\n",
      "Epoch 75/75\n",
      "5997/5997 [==============================] - 1s 94us/step - loss: 1.5465 - acc: 0.5291 - val_loss: 1.5714 - val_acc: 0.5130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159c10b00>"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lecun_model2 = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "lecun_model2.add(layers.Dense(256, kernel_initializer='lecun_normal',activation='relu', input_shape=(29,)))\n",
    "lecun_model2.add(layers.Dropout(0.4))\n",
    "\n",
    "# Add another hidden layer\n",
    "lecun_model2.add(layers.Dense(128,kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "lecun_model2.add(layers.Dropout(0.4))\n",
    "\n",
    "lecun_model2.add(layers.Dense(128,kernel_regularizer=regularizers.l2(0.005),activation='relu'))\n",
    "lecun_model2.add(layers.Dropout(0.4))\n",
    "# Add an output layer\n",
    "lecun_model2.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "lecun_model2.compile(optimizer='nadam', \n",
    "                      loss='sparse_categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "lecun_model2.fit(X_train,  y_train_lab, \n",
    "            epochs=75, validation_data=(X_val, y_val_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5997/5997 [==============================] - 0s 43us/step\n",
      "Training Loss: 1.34 \n",
      "Training Accuracy: 0.613\n",
      "----------\n",
      "1000/1000 [==============================] - 0s 39us/step\n",
      "Test Loss: 1.62 \n",
      "Test Accuracy: 0.502\n"
     ]
    }
   ],
   "source": [
    "results_train = lecun_model2.evaluate(X_train, y_train_lab)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = lecun_model2.evaluate(X_test, y_test_lab)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5997 samples, validate on 1000 samples\n",
      "Epoch 1/75\n",
      "5997/5997 [==============================] - 2s 349us/step - loss: 3.0421 - acc: 0.2623 - val_loss: 2.5431 - val_acc: 0.4160\n",
      "Epoch 2/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 2.4781 - acc: 0.3553 - val_loss: 2.1645 - val_acc: 0.4380\n",
      "Epoch 3/75\n",
      "5997/5997 [==============================] - 0s 33us/step - loss: 2.1803 - acc: 0.3822 - val_loss: 1.9473 - val_acc: 0.4330\n",
      "Epoch 4/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.9996 - acc: 0.4085 - val_loss: 1.8253 - val_acc: 0.4220\n",
      "Epoch 5/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.8787 - acc: 0.4137 - val_loss: 1.7463 - val_acc: 0.4410\n",
      "Epoch 6/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.8024 - acc: 0.4224 - val_loss: 1.6962 - val_acc: 0.4390\n",
      "Epoch 7/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.7503 - acc: 0.4324 - val_loss: 1.6428 - val_acc: 0.4600\n",
      "Epoch 8/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.7223 - acc: 0.4319 - val_loss: 1.6163 - val_acc: 0.4630\n",
      "Epoch 9/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.6934 - acc: 0.4442 - val_loss: 1.6033 - val_acc: 0.4580\n",
      "Epoch 10/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.6731 - acc: 0.4459 - val_loss: 1.5938 - val_acc: 0.4540\n",
      "Epoch 11/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.6524 - acc: 0.4507 - val_loss: 1.5708 - val_acc: 0.4570\n",
      "Epoch 12/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.6426 - acc: 0.4611 - val_loss: 1.5592 - val_acc: 0.4620\n",
      "Epoch 13/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.6260 - acc: 0.4567 - val_loss: 1.5853 - val_acc: 0.4640\n",
      "Epoch 14/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.6201 - acc: 0.4626 - val_loss: 1.5462 - val_acc: 0.4670\n",
      "Epoch 15/75\n",
      "5997/5997 [==============================] - 0s 29us/step - loss: 1.6101 - acc: 0.4641 - val_loss: 1.5372 - val_acc: 0.4930\n",
      "Epoch 16/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.6026 - acc: 0.4724 - val_loss: 1.5443 - val_acc: 0.4720\n",
      "Epoch 17/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.5942 - acc: 0.4767 - val_loss: 1.5289 - val_acc: 0.4780\n",
      "Epoch 18/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.5846 - acc: 0.4802 - val_loss: 1.5423 - val_acc: 0.4700\n",
      "Epoch 19/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5774 - acc: 0.4876 - val_loss: 1.5329 - val_acc: 0.4890\n",
      "Epoch 20/75\n",
      "5997/5997 [==============================] - 0s 29us/step - loss: 1.5817 - acc: 0.4867 - val_loss: 1.5430 - val_acc: 0.4640\n",
      "Epoch 21/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.5682 - acc: 0.4849 - val_loss: 1.5256 - val_acc: 0.4880\n",
      "Epoch 22/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5734 - acc: 0.4904 - val_loss: 1.5235 - val_acc: 0.4920\n",
      "Epoch 23/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5600 - acc: 0.4909 - val_loss: 1.5293 - val_acc: 0.4910\n",
      "Epoch 24/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5521 - acc: 0.4967 - val_loss: 1.5262 - val_acc: 0.4830\n",
      "Epoch 25/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5567 - acc: 0.5004 - val_loss: 1.5452 - val_acc: 0.4770\n",
      "Epoch 26/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.5426 - acc: 0.4994 - val_loss: 1.5342 - val_acc: 0.5020\n",
      "Epoch 27/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5494 - acc: 0.4967 - val_loss: 1.5226 - val_acc: 0.4980\n",
      "Epoch 28/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5445 - acc: 0.5033 - val_loss: 1.5551 - val_acc: 0.4820\n",
      "Epoch 29/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5396 - acc: 0.5094 - val_loss: 1.5435 - val_acc: 0.4670\n",
      "Epoch 30/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5250 - acc: 0.5043 - val_loss: 1.5188 - val_acc: 0.4980\n",
      "Epoch 31/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5250 - acc: 0.5111 - val_loss: 1.5239 - val_acc: 0.4810\n",
      "Epoch 32/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.5288 - acc: 0.5101 - val_loss: 1.5260 - val_acc: 0.4950\n",
      "Epoch 33/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5272 - acc: 0.5173 - val_loss: 1.5196 - val_acc: 0.5000\n",
      "Epoch 34/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5197 - acc: 0.5099 - val_loss: 1.5364 - val_acc: 0.4870\n",
      "Epoch 35/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5122 - acc: 0.5163 - val_loss: 1.5321 - val_acc: 0.4900\n",
      "Epoch 36/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5054 - acc: 0.5146 - val_loss: 1.5245 - val_acc: 0.4950\n",
      "Epoch 37/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.5114 - acc: 0.5191 - val_loss: 1.5238 - val_acc: 0.4980\n",
      "Epoch 38/75\n",
      "5997/5997 [==============================] - 0s 29us/step - loss: 1.5029 - acc: 0.5193 - val_loss: 1.5217 - val_acc: 0.4960\n",
      "Epoch 39/75\n",
      "5997/5997 [==============================] - 0s 29us/step - loss: 1.4967 - acc: 0.5244 - val_loss: 1.5130 - val_acc: 0.4990\n",
      "Epoch 40/75\n",
      "5997/5997 [==============================] - 0s 29us/step - loss: 1.5007 - acc: 0.5281 - val_loss: 1.5194 - val_acc: 0.4950\n",
      "Epoch 41/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.4869 - acc: 0.5268 - val_loss: 1.5085 - val_acc: 0.5080\n",
      "Epoch 42/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.4846 - acc: 0.5278 - val_loss: 1.5049 - val_acc: 0.5090\n",
      "Epoch 43/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.4832 - acc: 0.5301 - val_loss: 1.5200 - val_acc: 0.5060\n",
      "Epoch 44/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.4818 - acc: 0.5341 - val_loss: 1.5163 - val_acc: 0.5080\n",
      "Epoch 45/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.4899 - acc: 0.5238 - val_loss: 1.4999 - val_acc: 0.5260\n",
      "Epoch 46/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4773 - acc: 0.5314 - val_loss: 1.5115 - val_acc: 0.5090\n",
      "Epoch 47/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4877 - acc: 0.5263 - val_loss: 1.5043 - val_acc: 0.5130\n",
      "Epoch 48/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.4799 - acc: 0.5388 - val_loss: 1.5350 - val_acc: 0.4910\n",
      "Epoch 49/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.4769 - acc: 0.5381 - val_loss: 1.5143 - val_acc: 0.5070\n",
      "Epoch 50/75\n",
      "5997/5997 [==============================] - 0s 28us/step - loss: 1.4794 - acc: 0.5294 - val_loss: 1.5004 - val_acc: 0.5230\n",
      "Epoch 51/75\n",
      "5997/5997 [==============================] - 0s 27us/step - loss: 1.4738 - acc: 0.5349 - val_loss: 1.5094 - val_acc: 0.5080\n",
      "Epoch 52/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4734 - acc: 0.5319 - val_loss: 1.5130 - val_acc: 0.5080\n",
      "Epoch 53/75\n",
      "5997/5997 [==============================] - 0s 33us/step - loss: 1.4489 - acc: 0.5461 - val_loss: 1.5218 - val_acc: 0.5130\n",
      "Epoch 54/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.4811 - acc: 0.5331 - val_loss: 1.5203 - val_acc: 0.5080\n",
      "Epoch 55/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4527 - acc: 0.5514 - val_loss: 1.5154 - val_acc: 0.5060\n",
      "Epoch 56/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4566 - acc: 0.5451 - val_loss: 1.5184 - val_acc: 0.5130\n",
      "Epoch 57/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4624 - acc: 0.5429 - val_loss: 1.5291 - val_acc: 0.5000\n",
      "Epoch 58/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4573 - acc: 0.5473 - val_loss: 1.5062 - val_acc: 0.5030\n",
      "Epoch 59/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.4517 - acc: 0.5483 - val_loss: 1.5019 - val_acc: 0.5140\n",
      "Epoch 60/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.4397 - acc: 0.5454 - val_loss: 1.5083 - val_acc: 0.5200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4559 - acc: 0.5496 - val_loss: 1.5011 - val_acc: 0.5210\n",
      "Epoch 62/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4475 - acc: 0.5464 - val_loss: 1.5168 - val_acc: 0.5140\n",
      "Epoch 63/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.4392 - acc: 0.5586 - val_loss: 1.5076 - val_acc: 0.5130\n",
      "Epoch 64/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4434 - acc: 0.5561 - val_loss: 1.5328 - val_acc: 0.5130\n",
      "Epoch 65/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.4401 - acc: 0.5628 - val_loss: 1.5179 - val_acc: 0.4990\n",
      "Epoch 66/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4347 - acc: 0.5586 - val_loss: 1.5199 - val_acc: 0.5250\n",
      "Epoch 67/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4289 - acc: 0.5539 - val_loss: 1.5133 - val_acc: 0.5250\n",
      "Epoch 68/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4336 - acc: 0.5524 - val_loss: 1.5181 - val_acc: 0.5220\n",
      "Epoch 69/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.4249 - acc: 0.5596 - val_loss: 1.5129 - val_acc: 0.5290\n",
      "Epoch 70/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4285 - acc: 0.5588 - val_loss: 1.5051 - val_acc: 0.5310\n",
      "Epoch 71/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.4258 - acc: 0.5581 - val_loss: 1.5138 - val_acc: 0.5240\n",
      "Epoch 72/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.4254 - acc: 0.5579 - val_loss: 1.5055 - val_acc: 0.5250\n",
      "Epoch 73/75\n",
      "5997/5997 [==============================] - 0s 29us/step - loss: 1.4255 - acc: 0.5619 - val_loss: 1.5034 - val_acc: 0.5200\n",
      "Epoch 74/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4265 - acc: 0.5609 - val_loss: 1.4968 - val_acc: 0.5390\n",
      "Epoch 75/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.4061 - acc: 0.5680 - val_loss: 1.5163 - val_acc: 0.5250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15ad72dd8>"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lecun_model = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "lecun_model.add(layers.Dense(256, kernel_initializer='lecun_normal',activation='relu', input_shape=(29,)))\n",
    "lecun_model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Add another hidden layer\n",
    "lecun_model.add(layers.Dense(128,kernel_initializer='lecun_normal',kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "lecun_model.add(layers.Dropout(0.4))\n",
    "\n",
    "lecun_model.add(layers.Dense(128,kernel_initializer='lecun_normal',kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "lecun_model.add(layers.Dropout(0.4))\n",
    "\n",
    "# Add an output layer\n",
    "lecun_model.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "lecun_model.compile(optimizer='nadam', \n",
    "                      loss='sparse_categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "lecun_model.fit(X_train,  y_train_lab, epochs=75,\n",
    "                    batch_size=128, validation_data=(X_val, y_val_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5997/5997 [==============================] - 0s 43us/step\n",
      "Training Loss: 1.21 \n",
      "Training Accuracy: 0.65\n",
      "----------\n",
      "1000/1000 [==============================] - 0s 38us/step\n",
      "Test Loss: 1.58 \n",
      "Test Accuracy: 0.521\n"
     ]
    }
   ],
   "source": [
    "results_train = lecun_model.evaluate(X_train, y_train_lab)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = lecun_model.evaluate(X_test, y_test_lab)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5997 samples, validate on 1000 samples\n",
      "Epoch 1/75\n",
      "5997/5997 [==============================] - 2s 376us/step - loss: 3.0742 - acc: 0.2395 - val_loss: 2.6003 - val_acc: 0.3950\n",
      "Epoch 2/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 2.5256 - acc: 0.3322 - val_loss: 2.2136 - val_acc: 0.4070\n",
      "Epoch 3/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 2.2225 - acc: 0.3677 - val_loss: 2.0070 - val_acc: 0.4350\n",
      "Epoch 4/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 2.0290 - acc: 0.3904 - val_loss: 1.8495 - val_acc: 0.4390\n",
      "Epoch 5/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.9127 - acc: 0.3937 - val_loss: 1.7676 - val_acc: 0.4400\n",
      "Epoch 6/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.8307 - acc: 0.4057 - val_loss: 1.7023 - val_acc: 0.4520\n",
      "Epoch 7/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.7901 - acc: 0.4094 - val_loss: 1.6489 - val_acc: 0.4490\n",
      "Epoch 8/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.7510 - acc: 0.4239 - val_loss: 1.6274 - val_acc: 0.4450\n",
      "Epoch 9/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.7158 - acc: 0.4332 - val_loss: 1.5985 - val_acc: 0.4520\n",
      "Epoch 10/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.7065 - acc: 0.4309 - val_loss: 1.5865 - val_acc: 0.4660\n",
      "Epoch 11/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.6817 - acc: 0.4342 - val_loss: 1.5972 - val_acc: 0.4650\n",
      "Epoch 12/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.6722 - acc: 0.4389 - val_loss: 1.5671 - val_acc: 0.4580\n",
      "Epoch 13/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.6632 - acc: 0.4496 - val_loss: 1.5663 - val_acc: 0.4670\n",
      "Epoch 14/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.6473 - acc: 0.4542 - val_loss: 1.5705 - val_acc: 0.4650\n",
      "Epoch 15/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.6422 - acc: 0.4552 - val_loss: 1.5832 - val_acc: 0.4630\n",
      "Epoch 16/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.6291 - acc: 0.4571 - val_loss: 1.5501 - val_acc: 0.4690\n",
      "Epoch 17/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.6312 - acc: 0.4606 - val_loss: 1.5517 - val_acc: 0.4730\n",
      "Epoch 18/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.6117 - acc: 0.4632 - val_loss: 1.5582 - val_acc: 0.4570\n",
      "Epoch 19/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.6095 - acc: 0.4666 - val_loss: 1.5552 - val_acc: 0.4570\n",
      "Epoch 20/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.6049 - acc: 0.4702 - val_loss: 1.5521 - val_acc: 0.4750\n",
      "Epoch 21/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.6067 - acc: 0.4721 - val_loss: 1.5561 - val_acc: 0.4670\n",
      "Epoch 22/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.6079 - acc: 0.4712 - val_loss: 1.5309 - val_acc: 0.4740\n",
      "Epoch 23/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.5987 - acc: 0.4742 - val_loss: 1.5420 - val_acc: 0.4840\n",
      "Epoch 24/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5948 - acc: 0.4694 - val_loss: 1.5443 - val_acc: 0.4740\n",
      "Epoch 25/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.5917 - acc: 0.4784 - val_loss: 1.5415 - val_acc: 0.4780\n",
      "Epoch 26/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.5936 - acc: 0.4764 - val_loss: 1.5395 - val_acc: 0.4820\n",
      "Epoch 27/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.5730 - acc: 0.4897 - val_loss: 1.5346 - val_acc: 0.4760\n",
      "Epoch 28/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.5777 - acc: 0.4769 - val_loss: 1.5342 - val_acc: 0.4740\n",
      "Epoch 29/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5713 - acc: 0.4987 - val_loss: 1.5312 - val_acc: 0.4880\n",
      "Epoch 30/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.5712 - acc: 0.4869 - val_loss: 1.5258 - val_acc: 0.4880\n",
      "Epoch 31/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.5703 - acc: 0.4892 - val_loss: 1.5404 - val_acc: 0.4790\n",
      "Epoch 32/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5473 - acc: 0.4901 - val_loss: 1.5434 - val_acc: 0.4790\n",
      "Epoch 33/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5539 - acc: 0.4987 - val_loss: 1.5310 - val_acc: 0.4900\n",
      "Epoch 34/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5495 - acc: 0.4997 - val_loss: 1.5227 - val_acc: 0.4850\n",
      "Epoch 35/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.5576 - acc: 0.4914 - val_loss: 1.5131 - val_acc: 0.4970\n",
      "Epoch 36/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5388 - acc: 0.4966 - val_loss: 1.5180 - val_acc: 0.4920\n",
      "Epoch 37/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5421 - acc: 0.4964 - val_loss: 1.5183 - val_acc: 0.4850\n",
      "Epoch 38/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.5450 - acc: 0.4964 - val_loss: 1.5164 - val_acc: 0.4930\n",
      "Epoch 39/75\n",
      "5997/5997 [==============================] - 0s 29us/step - loss: 1.5426 - acc: 0.5031 - val_loss: 1.5082 - val_acc: 0.4850\n",
      "Epoch 40/75\n",
      "5997/5997 [==============================] - 0s 28us/step - loss: 1.5407 - acc: 0.4986 - val_loss: 1.5315 - val_acc: 0.4860\n",
      "Epoch 41/75\n",
      "5997/5997 [==============================] - 0s 28us/step - loss: 1.5295 - acc: 0.5089 - val_loss: 1.5113 - val_acc: 0.5090\n",
      "Epoch 42/75\n",
      "5997/5997 [==============================] - 0s 29us/step - loss: 1.5316 - acc: 0.5011 - val_loss: 1.5155 - val_acc: 0.4990\n",
      "Epoch 43/75\n",
      "5997/5997 [==============================] - 0s 30us/step - loss: 1.5226 - acc: 0.5054 - val_loss: 1.5108 - val_acc: 0.4930\n",
      "Epoch 44/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.5441 - acc: 0.5001 - val_loss: 1.5273 - val_acc: 0.4930\n",
      "Epoch 45/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.5217 - acc: 0.5139 - val_loss: 1.5189 - val_acc: 0.4910\n",
      "Epoch 46/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.5201 - acc: 0.5178 - val_loss: 1.5170 - val_acc: 0.4980\n",
      "Epoch 47/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.5354 - acc: 0.4996 - val_loss: 1.5081 - val_acc: 0.4970\n",
      "Epoch 48/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5205 - acc: 0.5093 - val_loss: 1.5089 - val_acc: 0.4990\n",
      "Epoch 49/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.5236 - acc: 0.5146 - val_loss: 1.5297 - val_acc: 0.4940\n",
      "Epoch 50/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.5204 - acc: 0.5136 - val_loss: 1.5099 - val_acc: 0.5040\n",
      "Epoch 51/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.5289 - acc: 0.5066 - val_loss: 1.5208 - val_acc: 0.5030\n",
      "Epoch 52/75\n",
      "5997/5997 [==============================] - 0s 33us/step - loss: 1.5070 - acc: 0.5209 - val_loss: 1.5193 - val_acc: 0.5060\n",
      "Epoch 53/75\n",
      "5997/5997 [==============================] - 0s 33us/step - loss: 1.5104 - acc: 0.5179 - val_loss: 1.5257 - val_acc: 0.4890\n",
      "Epoch 54/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.5137 - acc: 0.5204 - val_loss: 1.5184 - val_acc: 0.5000\n",
      "Epoch 55/75\n",
      "5997/5997 [==============================] - 0s 34us/step - loss: 1.4992 - acc: 0.5188 - val_loss: 1.5160 - val_acc: 0.5030\n",
      "Epoch 56/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.4934 - acc: 0.5274 - val_loss: 1.5065 - val_acc: 0.5100\n",
      "Epoch 57/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4984 - acc: 0.5213 - val_loss: 1.4966 - val_acc: 0.5160\n",
      "Epoch 58/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.4925 - acc: 0.5304 - val_loss: 1.4946 - val_acc: 0.4910\n",
      "Epoch 59/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.5002 - acc: 0.5253 - val_loss: 1.5045 - val_acc: 0.5040\n",
      "Epoch 60/75\n",
      "5997/5997 [==============================] - 0s 34us/step - loss: 1.5008 - acc: 0.5341 - val_loss: 1.5099 - val_acc: 0.5060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/75\n",
      "5997/5997 [==============================] - 0s 34us/step - loss: 1.4930 - acc: 0.5306 - val_loss: 1.4969 - val_acc: 0.4990\n",
      "Epoch 62/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4907 - acc: 0.5309 - val_loss: 1.5001 - val_acc: 0.5070\n",
      "Epoch 63/75\n",
      "5997/5997 [==============================] - 0s 33us/step - loss: 1.4959 - acc: 0.5259 - val_loss: 1.4930 - val_acc: 0.5180\n",
      "Epoch 64/75\n",
      "5997/5997 [==============================] - 0s 33us/step - loss: 1.4955 - acc: 0.5189 - val_loss: 1.5038 - val_acc: 0.5050\n",
      "Epoch 65/75\n",
      "5997/5997 [==============================] - 0s 32us/step - loss: 1.4838 - acc: 0.5338 - val_loss: 1.5161 - val_acc: 0.5080\n",
      "Epoch 66/75\n",
      "5997/5997 [==============================] - 0s 29us/step - loss: 1.4872 - acc: 0.5311 - val_loss: 1.5237 - val_acc: 0.5050\n",
      "Epoch 67/75\n",
      "5997/5997 [==============================] - 0s 31us/step - loss: 1.4760 - acc: 0.5314 - val_loss: 1.5187 - val_acc: 0.4970\n",
      "Epoch 68/75\n",
      "5997/5997 [==============================] - 0s 33us/step - loss: 1.4824 - acc: 0.5361 - val_loss: 1.5130 - val_acc: 0.5160\n",
      "Epoch 69/75\n",
      "5997/5997 [==============================] - 0s 33us/step - loss: 1.4650 - acc: 0.5394 - val_loss: 1.5033 - val_acc: 0.4980\n",
      "Epoch 70/75\n",
      "5997/5997 [==============================] - 0s 33us/step - loss: 1.4807 - acc: 0.5319 - val_loss: 1.4988 - val_acc: 0.5160\n",
      "Epoch 71/75\n",
      "5997/5997 [==============================] - 0s 34us/step - loss: 1.4739 - acc: 0.5359 - val_loss: 1.5025 - val_acc: 0.5090\n",
      "Epoch 72/75\n",
      "5997/5997 [==============================] - 0s 33us/step - loss: 1.4709 - acc: 0.5431 - val_loss: 1.5215 - val_acc: 0.5070\n",
      "Epoch 73/75\n",
      "5997/5997 [==============================] - 0s 33us/step - loss: 1.4619 - acc: 0.5503 - val_loss: 1.5037 - val_acc: 0.5160\n",
      "Epoch 74/75\n",
      "5997/5997 [==============================] - 0s 33us/step - loss: 1.4672 - acc: 0.5453 - val_loss: 1.5109 - val_acc: 0.5010\n",
      "Epoch 75/75\n",
      "5997/5997 [==============================] - 0s 33us/step - loss: 1.4702 - acc: 0.5376 - val_loss: 1.5194 - val_acc: 0.4990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15ce12d30>"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lecun_model3 = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "lecun_model3.add(layers.Dense(256, kernel_initializer='lecun_normal',activation='relu', input_shape=(29,)))\n",
    "lecun_model3.add(layers.Dropout(0.4))\n",
    "\n",
    "# Add another hidden layer\n",
    "lecun_model3.add(layers.Dense(128,kernel_initializer='lecun_normal',kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "lecun_model3.add(layers.Dropout(0.4))\n",
    "\n",
    "lecun_model3.add(layers.Dense(128,kernel_initializer='lecun_normal',kernel_regularizer=regularizers.l2(0.005), activation='relu'))\n",
    "lecun_model3.add(layers.Dropout(0.4))\n",
    "\n",
    "# Add an output layer\n",
    "lecun_model3.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "lecun_model3.compile(optimizer='nadam', \n",
    "                      loss='sparse_categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "lecun_model3.fit(X_train,  y_train_lab, epochs=75,\n",
    "                    batch_size=128, validation_data=(X_val, y_val_lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5997/5997 [==============================] - 0s 42us/step\n",
      "Training Loss: 1.29 \n",
      "Training Accuracy: 0.608\n",
      "----------\n",
      "1000/1000 [==============================] - 0s 39us/step\n",
      "Test Loss: 1.57 \n",
      "Test Accuracy: 0.509\n"
     ]
    }
   ],
   "source": [
    "results_train = lecun_model3.evaluate(X_train, y_train_lab)\n",
    "print(f'Training Loss: {results_train[0]:.3} \\nTraining Accuracy: {results_train[1]:.3}')\n",
    "\n",
    "print('----------')\n",
    "\n",
    "results_test = lecun_model3.evaluate(X_test, y_test_lab)\n",
    "print(f'Test Loss: {results_test[0]:.3} \\nTest Accuracy: {results_test[1]:.3}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 48us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5743236708641053, 0.502]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lecun_model3.evaluate(X_val, y_val_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5997/5997 [==============================] - 0s 44us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1556969517386912, 0.6731699183123577]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lecun_model3.evaluate(X_train,y_train_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
